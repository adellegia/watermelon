{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(r\"../data/df_final.json\")\n",
    "#df = pd.read_json(r\"../data/df_final_document.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 187\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Reference                     143 non-null    object\n",
      " 1   Feedback date                 143 non-null    object\n",
      " 2   User type                     112 non-null    object\n",
      " 3   Scope                         4 non-null      object\n",
      " 4   Organisation name             112 non-null    object\n",
      " 5   Transparency register number  93 non-null     object\n",
      " 6   Organisation size             112 non-null    object\n",
      " 7   label_132                     143 non-null    object\n",
      " 8   label_134                     143 non-null    object\n",
      " 9   submit                        143 non-null    int64 \n",
      " 10  file_name                     73 non-null     object\n",
      " 11  language                      143 non-null    object\n",
      " 12  text                          143 non-null    object\n",
      " 13  text_clean                    143 non-null    object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label.132'] = le.fit_transform(df['label_132'])\n",
    "df['label.134'] = le.fit_transform(df['label_134'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    73\n",
       "0    70\n",
       "Name: submit, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['submit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use pdf submissions\n",
    "df = df[df['submit']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='count', ascending=False)[['Reference', 'count']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(df['count']).hist(bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT multi-classification (K=2) using Q132/label.132"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/?\n",
    "\n",
    "https://trishalaneeraj.github.io/2020-04-04/feature-based-approach-with-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janinedevera/opt/miniconda3/envs/tad-project/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import yaml\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, test, validation sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text_clean'], df['label.132'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label.132'])\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(train_text))\n",
    "print(len(val_text))\n",
    "print(len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import BERT Model and BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "# get length of all the messages in the train set\n",
    "seq_len = [len(str(i).split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janinedevera/opt/miniconda3/envs/tad-project/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 2\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janinedevera/opt/miniconda3/envs/tad-project/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5)          # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [1.0625     0.94444444]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_labels),\n",
    "                                        y = train_labels                                                    \n",
    "                                    )\n",
    "\n",
    "class_weights\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 200 batches.\n",
    "    # if step % 200 == 0 and not step == 0:\n",
    "    #   print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  #print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 200 batches.\n",
    "    # if step % 200 == 0 and not step == 0:\n",
    "      \n",
    "    #   # Calculate elapsed time in minutes.\n",
    "    #   #elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "    #   # Report progress.\n",
    "    #   print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 20\n",
      "\n",
      "Training Loss: 0.703\n",
      "Validation Loss: 0.700\n",
      "\n",
      " Epoch 2 / 20\n",
      "\n",
      "Training Loss: 0.689\n",
      "Validation Loss: 0.697\n",
      "\n",
      " Epoch 3 / 20\n",
      "\n",
      "Training Loss: 0.688\n",
      "Validation Loss: 0.696\n",
      "\n",
      " Epoch 4 / 20\n",
      "\n",
      "Training Loss: 0.686\n",
      "Validation Loss: 0.698\n",
      "\n",
      " Epoch 5 / 20\n",
      "\n",
      "Training Loss: 0.686\n",
      "Validation Loss: 0.697\n",
      "\n",
      " Epoch 6 / 20\n",
      "\n",
      "Training Loss: 0.686\n",
      "Validation Loss: 0.696\n",
      "\n",
      " Epoch 7 / 20\n",
      "\n",
      "Training Loss: 0.686\n",
      "Validation Loss: 0.696\n",
      "\n",
      " Epoch 8 / 20\n",
      "\n",
      "Training Loss: 0.688\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 9 / 20\n",
      "\n",
      "Training Loss: 0.687\n",
      "Validation Loss: 0.691\n",
      "\n",
      " Epoch 10 / 20\n",
      "\n",
      "Training Loss: 0.693\n",
      "Validation Loss: 0.694\n",
      "\n",
      " Epoch 11 / 20\n",
      "\n",
      "Training Loss: 0.683\n",
      "Validation Loss: 0.695\n",
      "\n",
      " Epoch 12 / 20\n",
      "\n",
      "Training Loss: 0.684\n",
      "Validation Loss: 0.693\n",
      "\n",
      " Epoch 13 / 20\n",
      "\n",
      "Training Loss: 0.677\n",
      "Validation Loss: 0.688\n",
      "\n",
      " Epoch 14 / 20\n",
      "\n",
      "Training Loss: 0.691\n",
      "Validation Loss: 0.687\n",
      "\n",
      " Epoch 15 / 20\n",
      "\n",
      "Training Loss: 0.684\n",
      "Validation Loss: 0.687\n",
      "\n",
      " Epoch 16 / 20\n",
      "\n",
      "Training Loss: 0.676\n",
      "Validation Loss: 0.685\n",
      "\n",
      " Epoch 17 / 20\n",
      "\n",
      "Training Loss: 0.698\n",
      "Validation Loss: 0.691\n",
      "\n",
      " Epoch 18 / 20\n",
      "\n",
      "Training Loss: 0.684\n",
      "Validation Loss: 0.686\n",
      "\n",
      " Epoch 19 / 20\n",
      "\n",
      "Training Loss: 0.687\n",
      "Validation Loss: 0.690\n",
      "\n",
      " Epoch 20 / 20\n",
      "\n",
      "Training Loss: 0.677\n",
      "Validation Loss: 0.685\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.73      0.72      0.72        11\n",
      "weighted avg       0.73      0.73      0.72        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    39\n",
       "0    34\n",
       "Name: label.132, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label.132'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 73 entries, 1 to 181\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Reference                     73 non-null     object\n",
      " 1   Feedback date                 73 non-null     object\n",
      " 2   User type                     65 non-null     object\n",
      " 3   Scope                         2 non-null      object\n",
      " 4   Organisation name             65 non-null     object\n",
      " 5   Transparency register number  52 non-null     object\n",
      " 6   Organisation size             65 non-null     object\n",
      " 7   label_132                     73 non-null     object\n",
      " 8   label_134                     73 non-null     object\n",
      " 9   submit                        73 non-null     int64 \n",
      " 10  file_name                     73 non-null     object\n",
      " 11  language                      73 non-null     object\n",
      " 12  text                          73 non-null     object\n",
      " 13  text_clean                    73 non-null     object\n",
      " 14  label.132                     73 non-null     int64 \n",
      " 15  label.134                     73 non-null     int64 \n",
      "dtypes: int64(3), object(13)\n",
      "memory usage: 9.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for tf-idf word embeddings:\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tad-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cab4409ce5d224ee9075dc374e4bd34bc4b9571e804fbf24e5d7f1c9b19a09d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
