{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_json(r\"../data/df_final_para.json\") # paragraphs - 3776\n",
    "df = pd.read_json(r\"../data/df_final_document.json\") # document - 143 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 187\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Reference                     143 non-null    object\n",
      " 1   Feedback date                 143 non-null    object\n",
      " 2   User type                     112 non-null    object\n",
      " 3   Scope                         4 non-null      object\n",
      " 4   Organisation name             112 non-null    object\n",
      " 5   Transparency register number  93 non-null     object\n",
      " 6   Organisation size             112 non-null    object\n",
      " 7   label_132                     143 non-null    object\n",
      " 8   label_134                     143 non-null    object\n",
      " 9   submit                        143 non-null    int64 \n",
      " 10  file_name                     73 non-null     object\n",
      " 11  language                      143 non-null    object\n",
      " 12  text                          143 non-null    object\n",
      " 13  text_clean                    143 non-null    object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label.132'] = le.fit_transform(df['label_132'])\n",
    "df['label.134'] = le.fit_transform(df['label_134'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    73\n",
       "0    70\n",
       "Name: submit, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['submit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use pdf submissions\n",
    "df = df[df['submit']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_values(by='count', ascending=False)[['Reference', 'count']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(df['count']).hist(bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT multi-classification (K=2) using Q132/label.132"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/?\n",
    "\n",
    "https://trishalaneeraj.github.io/2020-04-04/feature-based-approach-with-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import yaml\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, test, validation sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text_clean'], df['label.132'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label.132'])\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(train_text))\n",
    "print(len(val_text))\n",
    "print(len(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import BERT Model and BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "# get length of all the messages in the train set\n",
    "seq_len = [len(str(i).split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 2\n",
    "num_workers = 2\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, num_workers=num_workers, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, num_workers=num_workers, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to freeze all the parameters if freeze = T\n",
    "def set_parameter_requires_grad(model, freeze):\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all parameters\n",
    "set_parameter_requires_grad(model=bert, freeze=True)\n",
    "\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5)          # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [1.0625     0.94444444]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_labels),\n",
    "                                        y = train_labels                                                    \n",
    "                                    )\n",
    "\n",
    "class_weights\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "criterion  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2f4d0553c140d78e8f2a5e6c69410b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  101, 10093, 12879, 12356,  2050,  1521, 24501, 26029,  2015,  1040,\n",
      "          2290,  4012,  2361,  1521, 23363,  7634,  2047,  4012, 22327,  4183,\n",
      "          6994, 17419,  6633,  2497,   102],\n",
      "        [  101, 25416,  2024,  5709,  1013,  5641,  1013, 12609, 10613,  1011,\n",
      "          2522,  3351,  3540,  1053,  3501,  5354, 24087,  1024,  1016,  1011,\n",
      "          1042,  2290,  1013, 15488,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  4962,  2099,\n",
      "          5136,  2047,  7327,  4012, 22327,  4183,  6994, 12919,  4012, 22327,\n",
      "          4183,  4372, 29278,  2278,   102],\n",
      "        [  101, 13433, 28032,  3259, 17419,  6633,  2497,  4012, 15630,  2015,\n",
      "         23363,  2047,  4012, 22327,  4183,  6994,  3145,  6752,  8490,  9944,\n",
      "          9006,  5017,  2278,  3745,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 1])]\n",
      "[tensor([[  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  3802,  3630,\n",
      "          1011, 28177,  2863, 13433, 28032,  3259,  2047,  4012, 22327,  4183,\n",
      "          6994, 17419,  6633,  2497,   102],\n",
      "        [  101, 13433, 28032,  3259,  3796, 11819, 19723,  5313,  2233,  2647,\n",
      "          2911,  4842,  1521,  2473,  2630,  8400,  3857,  1038,  2140, 16872,\n",
      "          1037,  1012, 12569,  2121,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 1])]\n",
      "[tensor([[  101,  4895,  2594,  5596,  4183,  2177, 25204,  2224,  2006,  3669,\n",
      "         25416,  2024,  5511,  1013,  5641,  1013, 12609,  4012, 24759,  2937,\n",
      "          2278,  3424, 24669,  7221,   102],\n",
      "        [  101, 16021,  6494,  2102,  2647,  9154,  4101, 23363,  2647,  4012,\n",
      "         15630,  2015,  1521, 15340, 14262,  7903,  2552,  5308,  8490, 16233,\n",
      "          2050,  4654, 14405, 21618,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 1])]\n",
      "[tensor([[  101, 11703,  6633,  2497,  4012, 22327,  4183, 15775, 12179,  2290,\n",
      "         15340,  3006,  1516, 13433, 28032,  3259,  3145,  6752,  8490,  8040,\n",
      "          4048,  5910,  2102, 25204,   102],\n",
      "        [  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609, 14925,  3736,\n",
      "          9530, 18886,  8569,  2102,  2647,  4012, 15630,  2015, 23363,  2047,\n",
      "          4012, 22327,  4183,  6994,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 0])]\n",
      "[tensor([[  101,  2047,  4012, 22327,  4183,  6994, 13433, 28032,  3259,  2865,\n",
      "         13462,  1055,  1012,  1052,  1012,  1037,  1012, 17174,  8566,  6593,\n",
      "          2865, 13462,  2052,  2057,   102],\n",
      "        [  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  7327,  1040,\n",
      "          1055,  1037,  1050,  1039,  1056,  1516,  1045, 23806,  9413,  7903,\n",
      "         14931,  1041,  2860, 18168,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 1])]\n",
      "[tensor([[  101,  2009,  2898,  2464, 14262,  3695,  2226,  3291,  2647,  2092,\n",
      "         25204,  2006,  6970, 25918,  7661,  4149, 26885,  2028, 25204, 26885,\n",
      "          7027, 24655,  3669,  4942,   102],\n",
      "        [  101, 13433, 28032,  3259,  7327,  4012, 15630,  2015,  1521, 17678,\n",
      "          2891,  2047,  4012, 22327,  4183,  6994,  4654,  1011, 14405, 19723,\n",
      "          5313,  4796,  1011, 10684,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  9657,  2072,\n",
      "         17827,  2000, 17727,  7911,  4942, 15630,  2015,  2647,  4012, 15630,\n",
      "          2015,  1521,  2270, 23363,   102],\n",
      "        [  101, 16021,  6494,  2102,  2647,  9154,  1521,  4101,  9530, 18886,\n",
      "          8569,  2102,  7327, 23363,  2047,  4012, 22327,  4183,  6994, 13316,\n",
      "          2102, 16021,  6494,  2102,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 1])]\n",
      "[tensor([[  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  9824,  1516,\n",
      "          2131, 16233,  2050,  2157,  2122,  2364,  4736,  2240, 16233,  2050,\n",
      "          2139, 14479, 13366,  2378,   102],\n",
      "        [  101, 17419,  6633,  2497,  1996,  7327, 15340, 14262,  7903,  2552,\n",
      "          2009,  2072,  3193, 16233,  2050,  3160, 26416,  2099,  1523,  2047,\n",
      "          4012, 22327,  4183,  6994,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 0])]\n",
      "[tensor([[  101,  1996,  2647,  4012, 15630,  2015,  1521, 15340, 14262,  7903,\n",
      "          2552, 17678,  2891,  7513,  1521,  3193, 15340,  3647,  3775, 17419,\n",
      "          6633,  2497,  7513,  2057,   102],\n",
      "        [  101,  1996,  6869,  4013, 17258,  3437,  3160, 15547,  2015,  2930,\n",
      "          1039,  1040,  2918, 12367,  2490, 23408,  3593,  3423, 10975, 28804,\n",
      "          7634,  5588,  3006,  2065,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101, 25416,  2024,  5511,  1013,  5641,  1013, 12609, 10797,  9944,\n",
      "          2361,  2030,  5654,  3193,  2047,  4012, 22327,  4183,  6994,  4132,\n",
      "         19723,  5313, 17678,  2891,   102],\n",
      "        [  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  9530, 18886,\n",
      "          8569,  2102,  8909, 25818,  4215,  2692,  2575,  2487,  1011,  3968,\n",
      "         27717,  1011, 23285,  2278,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 1])]\n",
      "[tensor([[  101, 29536,  2850, 14876,  2078,  2177, 24501, 26029,  2015,  2270,\n",
      "         23363,  2047,  2099,  5766,  2546,  2572,  2890,  4523,  1016,  2102,\n",
      "          2692,  2072,  2475,  2102,   102],\n",
      "        [  101, 25416,  2024,  5511,  1013,  5641,  1013, 12609,  4895, 27265,\n",
      "          2140,  3677,  4180,  5549,  2099,  4433, 17678,  2891,  2393,  8081,\n",
      "          4012, 22327,  4183,  4071,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 1])]\n",
      "[tensor([[  101,  5695,  4574,  1997,  4012,  5017,  2278,  7479,  1012, 18033,\n",
      "          5484,  2232,  6299,  2615,  1012,  1040,  2243,  1038, 16415, 22573,\n",
      "          2078, 18558, 18033,  5484,   102],\n",
      "        [  101,  2552,  2566, 13102, 22471,  2006,  1996,  2047,  4012, 22327,\n",
      "          4183,  6994,  2257,  3931,  2552,  2566, 13102, 22471,  2006,  1996,\n",
      "          2047,  4012, 22327,  4183,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 0])]\n",
      "[tensor([[  101, 25416,  2024,  5709,  1013,  5641,  1013, 12609,  4861,  2647,\n",
      "          4012, 15630,  2015,  1521,  1999, 25090,  2047,  2971,  1011,  2375,\n",
      "          6994, 15340, 14262,  7903,   102],\n",
      "        [  101,  5511,  1012,  5641,  1012, 12609,  2047,  4012, 22327,  4183,\n",
      "          6994, 27885,  8043,  2615,  6123,  4012, 15630,  2015,  1521,  2270,\n",
      "         23363, 17174,  8566,  6593,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101,  1996, 18816,  2100,  5679,  1037,  2529,  1011,  9358,  2099,\n",
      "         14017,  4904,  3229, 24951,  2290,  3745,  2711,  2951, 16215,  2072,\n",
      "          3259,  2556,  2711,  2951,   102],\n",
      "        [  101,  3423,  6771,  4748, 25300,  3367,  2099, 15620,  2072, 21871,\n",
      "          2072,  1011,  2175,  6692,  7559,  4783,  1021,  1012,  1023,  1012,\n",
      "         12609,  1996,  4012, 15630,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101,  7327,  3604,  6627, 13433, 28032,  3259,  4654, 14405, 19723,\n",
      "          5313, 13711,  4012, 22327,  4183,  2375, 15340,  3690,  1045, 17174,\n",
      "          8566,  6593, 16215,  2072,   102],\n",
      "        [  101, 25416,  2024,  5511,  1013,  5641,  1013, 12609,  2000,  2647,\n",
      "          4012, 15630,  2015, 13634,  1011,  4962,  2099,  4012, 22327,  4183,\n",
      "          3131,  1037,  1012,  1015,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 1])]\n",
      "[tensor([[  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  1996,  9530,\n",
      "         17421, 29536,  2594,  9944,  2361,  1040,  1055,  1037,  1041,  1037,\n",
      "          1054,  1050,  1045, 23806,   102],\n",
      "        [  101,  7327,  4012, 15630,  2015, 23363,  2047,  4012, 22327,  4183,\n",
      "          6994,  1035,  1035,  1035,  1035,  1035,  1035,  1035,  1035,  1035,\n",
      "          1035,  1035,  1035,  1035,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609, 28177,  2863,\n",
      "          1011,  3802,  3630, 13433, 28032,  3259,  2047,  4012, 22327,  4183,\n",
      "          6994, 17419,  6633,  2497,   102],\n",
      "        [  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  5616,  1011,\n",
      "          4372,  4502,  7615,  1996,  4297, 23606,  4254,  4632,  2270, 23363,\n",
      "          2047,  4012, 22327,  4183,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  2006,  2278,\n",
      "         28667,  8649,  2078, 17338,  3630,  4328,  4094,  9531, 10514,  9397,\n",
      "          3669,  5157,  2217,  3006,   102],\n",
      "        [  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609, 17419,  6633,\n",
      "          2497,  5160, 11708,  1999,  6201,  4957, 20051, 16681, 17244,  8586,\n",
      "          2239, 24501, 26029,  2015,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101, 25416,  2024,  2184,  1013,  5641,  1013, 12609,  1996, 23853,\n",
      "         18847, 18155,  2072,  2129,  4132,  3813,  2024, 15775, 12179,  2290,\n",
      "          2647,  4012, 22327,  4183,   102],\n",
      "        [  101,  2047,  4012, 22327,  4183,  6994,  1516, 23363, 14324,  9050,\n",
      "          5804, 14324,  9050,  5804,  7367,  2522,  1012,  4705, 11057, 14324,\n",
      "          9050,  5804,  5396, 14262,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 1])]\n",
      "[tensor([[  101,  1996,  9933,  4012, 23041,  3166,  1521, 11581, 24501, 26029,\n",
      "          2015,  2647,  4012, 15630,  2015,  1521, 23363, 15340, 14262,  7903,\n",
      "          2552,  2047,  4012, 22327,   102],\n",
      "        [  101, 25416,  2024,  5709,  1013,  5641,  1013, 12609,  2739,  5396,\n",
      "          9944,  2361,  4942, 15630,  2015,  2647,  4012, 15630,  2015,  2270,\n",
      "         23363,  1523, 15340, 14262,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 1])]\n",
      "[tensor([[  101, 25416,  2024,  5511,  1013,  5641,  1013, 12609, 17419,  6633,\n",
      "          2497,  2647,  4012, 15630,  2015,  1521,  2270, 23363, 17678,  2891,\n",
      "          2047,  4012, 22327,  4183,   102],\n",
      "        [  101, 17419,  6633,  2497,  2055,  2065,  8197,  2065,  8197, 16360,\n",
      "          6072,  3037,  2501, 27746, 18886,  2088,  9148,  2094,  2057,  1015,\n",
      "          1010,  3998,  2266,  2105,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 0])]\n",
      "[tensor([[  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  1996, 17678,\n",
      "          2891, 13675,  5243,  2102,  1520,  2047,  4012, 22327,  4183,  6994,\n",
      "          1521, 17174,  8566,  6593,   102],\n",
      "        [  101, 25416,  2024,  5641,  1013,  5641,  1013, 12609,  1996,  7327,\n",
      "         14794, 27746, 18886,  1996,  4254,  1997,  1996,  7327,  3119,  2033,\n",
      "          3022,  3126,  2006,  1996,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 0])]\n",
      "[tensor([[  101, 17419, 15340, 14262,  7903,  2552,  2047,  4012, 22327,  4183,\n",
      "          6994,  4682, 19034, 24501, 26029,  2015,  2270, 23363,  4682, 19034,\n",
      "          2400,  1011,  2663,  4988,   102],\n",
      "        [  101,  2003,  2546, 13433, 28032,  3259, 17678,  2891,  2047,  4012,\n",
      "         22327,  4183,  6994,  9099, 19362, 20588,  2102,  8909,  2193, 16327,\n",
      "         20842, 26224, 21926,  2575,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([1, 0])]\n",
      "[tensor([[  101,  7615,  2647,  4012, 15630,  2015,  1521, 23363, 13433, 18719,\n",
      "         16558,  2047,  4012, 22327,  4183,  6994, 17419,  6633,  2497,  1996,\n",
      "          1057,  1012,  1055,  1012,   102],\n",
      "        [  101, 17124,  4189,  3617,  2483,  6728,  6442,  4609,  5041,  5317,\n",
      "          4183,  2655,  2588,  7327, 11703,  2483,  9338,  2404,  2830,  4190,\n",
      "          2483,  2140,  4372, 26210,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0, 1])]\n",
      "[tensor([[  101, 25416,  2024,  5511,  1013,  5641,  1013, 12609,  8116,  2072,\n",
      "          5394,  7367,  2030,  7088, 12059,  2358,  2099,  4068,  1052,  1009,\n",
      "          4749,  1059,  7479,  1012,   102]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]]), tensor([0])]\n"
     ]
    }
   ],
   "source": [
    "for x, batch in enumerate(tqdm(train_dataloader)):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train(model, dataloader, criterion, optimizer):\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for i, batch  in enumerate(tqdm(dataloader)):\n",
    "    \n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = criterion(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # push model predictions to cpu\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate(model, dataloader, criterion):\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for i, batch in enumerate(tqdm(dataloader)):\n",
    "    \n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = criterion(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3926ba799ec4d52a1917a63c73337f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb665af081e4f709dccec2993c1996c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.685\n",
      "Validation Loss: 0.689\n",
      "\n",
      " Epoch 2 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d3e868ca4540f29cce37429279a8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591256f246ea45dea4db524510e6fbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.697\n",
      "Validation Loss: 0.684\n",
      "\n",
      " Epoch 3 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137a8d192f1849b08334019a4450cee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224296566b844beb9945bbf689125858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.689\n",
      "Validation Loss: 0.684\n",
      "\n",
      " Epoch 4 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fae3b71edd4a0d95e2b4486f3b1633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b9ad15c5dc494bad47c8c5c16ab2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.667\n",
      "Validation Loss: 0.680\n",
      "\n",
      " Epoch 5 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3fc66f283d4e8d889a455a0048dda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a0b41e084849eb81547915218221b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.670\n",
      "Validation Loss: 0.691\n",
      "\n",
      " Epoch 6 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261757707d1340ec94b9bc3463fa0f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c8729a4f61449dbf961bdd47356f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.681\n",
      "Validation Loss: 0.681\n",
      "\n",
      " Epoch 7 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5185e7bb04242a9ab0ad5bd387e4be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce8a347762d47209a02a0cedac3a01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.681\n",
      "Validation Loss: 0.690\n",
      "\n",
      " Epoch 8 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d559c41ad5f4466f99b5fad84660ede6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7cd61d96a7445f95012c909c0b5d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.684\n",
      "Validation Loss: 0.681\n",
      "\n",
      " Epoch 9 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2672fab8066a43d8bbb824577bbd4a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f813cb3f9e3545528d28486ad09a0243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.681\n",
      "Validation Loss: 0.689\n",
      "\n",
      " Epoch 10 / 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db870dca10af45dc984828b156add5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [117], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, epochs))\n\u001b[0;32m     13\u001b[0m \u001b[39m#train model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m train_loss, _ \u001b[39m=\u001b[39m train(model, train_dataloader, criterion, optimizer)\n\u001b[0;32m     16\u001b[0m \u001b[39m#evaluate model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m valid_loss, _ \u001b[39m=\u001b[39m evaluate(model, val_dataloader, criterion)\n",
      "Cell \u001b[1;32mIn [115], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer)\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[39m.\u001b[39mzero_grad()        \n\u001b[0;32m     21\u001b[0m \u001b[39m# get model predictions for the current batch\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m preds \u001b[39m=\u001b[39m model(sent_id, mask)\n\u001b[0;32m     24\u001b[0m \u001b[39m# compute the loss between actual and predicted values\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss \u001b[39m=\u001b[39m criterion(preds, labels)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn [54], line 28\u001b[0m, in \u001b[0;36mBERT_Arch.forward\u001b[1;34m(self, sent_id, mask)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, sent_id, mask):\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m   \u001b[39m#pass the inputs to the model  \u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m   _, cls_hs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(sent_id, attention_mask\u001b[39m=\u001b[39;49mmask)\n\u001b[0;32m     30\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(cls_hs)\n\u001b[0;32m     32\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1005\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1007\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1008\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1009\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1015\u001b[0m     embedding_output,\n\u001b[0;32m   1016\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1017\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1018\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1019\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1020\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1021\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1022\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1023\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1024\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1025\u001b[0m )\n\u001b[0;32m   1026\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1027\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    594\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    595\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    596\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    602\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 603\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    604\u001b[0m         hidden_states,\n\u001b[0;32m    605\u001b[0m         attention_mask,\n\u001b[0;32m    606\u001b[0m         layer_head_mask,\n\u001b[0;32m    607\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    608\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    609\u001b[0m         past_key_value,\n\u001b[0;32m    610\u001b[0m         output_attentions,\n\u001b[0;32m    611\u001b[0m     )\n\u001b[0;32m    613\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    614\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:531\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    528\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    529\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 531\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    532\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    533\u001b[0m )\n\u001b[0;32m    534\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    536\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 246\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:544\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m    543\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 544\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[0;32m    545\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:457\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    456\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[1;32m--> 457\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(hidden_states)\n\u001b[0;32m    458\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n\u001b[0;32m    459\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\torch\\nn\\functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[1;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train(model, train_dataloader, criterion, optimizer)\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate(model, val_dataloader, criterion)\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'Training Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.73      0.72      0.72        11\n",
      "weighted avg       0.73      0.73      0.72        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    39\n",
       "0    34\n",
       "Name: label.132, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label.132'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 73 entries, 1 to 181\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Reference                     73 non-null     object\n",
      " 1   Feedback date                 73 non-null     object\n",
      " 2   User type                     65 non-null     object\n",
      " 3   Scope                         2 non-null      object\n",
      " 4   Organisation name             65 non-null     object\n",
      " 5   Transparency register number  52 non-null     object\n",
      " 6   Organisation size             65 non-null     object\n",
      " 7   label_132                     73 non-null     object\n",
      " 8   label_134                     73 non-null     object\n",
      " 9   submit                        73 non-null     int64 \n",
      " 10  file_name                     73 non-null     object\n",
      " 11  language                      73 non-null     object\n",
      " 12  text                          73 non-null     object\n",
      " 13  text_clean                    73 non-null     object\n",
      " 14  label.132                     73 non-null     int64 \n",
      " 15  label.134                     73 non-null     int64 \n",
      "dtypes: int64(3), object(13)\n",
      "memory usage: 9.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for tf-idf word embeddings:\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermelon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74d1cbe4299d6052562a3b04e5d47e1706bc319f6acfc872fba2a82cb1a428da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
