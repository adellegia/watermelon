{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(r\"../data/df_final_para.json\") # paragraphs\n",
    "df = pd.read_json(r\"../data/df_final_document.json\") # document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 0 to 187\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Reference                     143 non-null    object\n",
      " 1   Feedback date                 143 non-null    object\n",
      " 2   User type                     112 non-null    object\n",
      " 3   Scope                         4 non-null      object\n",
      " 4   Organisation name             112 non-null    object\n",
      " 5   Transparency register number  93 non-null     object\n",
      " 6   Organisation size             112 non-null    object\n",
      " 7   label_132                     143 non-null    object\n",
      " 8   label_134                     143 non-null    object\n",
      " 9   submit                        143 non-null    int64 \n",
      " 10  file_name                     73 non-null     object\n",
      " 11  language                      143 non-null    object\n",
      " 12  text                          143 non-null    object\n",
      " 13  text_clean                    143 non-null    object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 16.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label.132'] = le.fit_transform(df['label_132'])\n",
    "df['label.134'] = le.fit_transform(df['label_134'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    73\n",
       "0    70\n",
       "Name: submit, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['submit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use pdf submissions\n",
    "df = df[df['submit']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='count', ascending=False)[['Reference', 'count']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(df['count']).hist(bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT multi-classification (K=2) using Q132/label.132"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/?\n",
    "\n",
    "https://trishalaneeraj.github.io/2020-04-04/feature-based-approach-with-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janinedevera/opt/miniconda3/envs/tad-project/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import yaml\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, test, validation sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text_clean'], df['label.132'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['label.132'])\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(train_text))\n",
    "print(len(val_text))\n",
    "print(len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import BERT Model and BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data\n",
    "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode text\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "print(sent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmYUlEQVR4nO3df3RU9Z3/8dcAw0BykmjIYhhIgHq0WEJxBX+zEqwJTfkh61mrhsVUW1crqCyuBdZlmbQq2p7DYU9Ztfa0yh434h8W1l1cMe6C4AItJOCCriA2ggvGLBQyQMpwTT77x34zX4eZhGTmzie5t8/HOXN0PvdzP/fzns9c5+XMnUzAGGMEAABgyYC+ngAAAPjDQvgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYNWgvp7A+To6OnT06FHl5eUpEAj09XQAAEAPGGN06tQphcNhDRjQ/Xsb/S58HD16VCUlJX09DQAAkIZPP/1Uo0aN6rZPvwsfeXl5kv5v8vn5+WmN4TiO3nrrLVVWVioYDLo5vX6DGv3B7zX6vT6JGv2CGjMXjUZVUlISfx3vTr8LH50fteTn52cUPnJycpSfn+/rJxE1ep/fa/R7fRI1+gU1uqcnl0xwwSkAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwa1NcTsG3Mkg1p7/vJ0zNcnAkAAH+YeOcDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGBVr8PHli1bNGvWLIXDYQUCAa1fvz6pz3/9139p9uzZKigoUF5enq677jodPnzYjfkCAACP63X4OHPmjCZOnKjVq1en3P7xxx9rypQpGjdunDZv3qz33ntPy5Yt05AhQzKeLAAA8L5Bvd2hqqpKVVVVXW5//PHH9a1vfUs//vGP421f+cpX0psdAADwnV6Hj+50dHRow4YN+sEPfqDp06dr9+7dGjt2rJYuXao5c+ak3CcWiykWi8XvR6NRSZLjOHIcJ615dO6Xav/QQJPWmF2N11e6q9EvqNH7/F6fRI1+QY3ujd8TAWNM2q/GgUBA69atiweL5uZmjRgxQjk5OXriiSc0bdo0vfnmm/rrv/5rbdq0SVOnTk0aIxKJqLa2Nqm9rq5OOTk56U4NAABY1NbWpurqarW2tio/P7/bvq6Gj6NHj2rkyJG66667VFdXF+83e/Zs5ebm6pVXXkkaI9U7HyUlJTp27NgFJ98Vx3FUX1+viooKBYPBhG1lkY1pjSlJ+yLT097Xbd3V6BfU6H1+r0+iRr+gxsxFo1EVFRX1KHy4+rFLUVGRBg0apK997WsJ7VdccYXefffdlPuEQiGFQqGk9mAwmPGDk2qMWHsgo/H6Gzcep/6OGr3P7/VJ1OgX1JjZuD3l6t/5GDx4sK6++mrt378/of3AgQMaPXq0m4cCAAAe1et3Pk6fPq2DBw/G7zc1NWnPnj0qLCxUaWmpHnvsMd1xxx266aab4td8/PM//7M2b97s5rwBAIBH9Tp87Nq1S9OmTYvfX7RokSSppqZGL730kv70T/9Uzz//vFasWKGHH35YX/3qV/Xaa69pypQp7s0aAAB4Vq/DR3l5uS50jeq9996re++9N+1JAQAA/+K3XQAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgVa/Dx5YtWzRr1iyFw2EFAgGtX7++y77333+/AoGAVq1alcEUAQCAn/Q6fJw5c0YTJ07U6tWru+23fv16/frXv1Y4HE57cgAAwH8G9XaHqqoqVVVVddvnyJEjWrBggTZu3KgZM2akPTkAAOA/vQ4fF9LR0aF58+bpscce0/jx4y/YPxaLKRaLxe9Ho1FJkuM4chwnrTl07pdq/9BAk9aYXY3XV7qr0S+o0fv8Xp9EjX5Bje6N3xMBY0zar8aBQEDr1q3TnDlz4m0rVqzQpk2btHHjRgUCAY0ZM0YLFy7UwoULU44RiURUW1ub1F5XV6ecnJx0pwYAACxqa2tTdXW1WltblZ+f321fV9/5aGho0N/93d+psbFRgUCgR/ssXbpUixYtit+PRqMqKSlRZWXlBSffFcdxVF9fr4qKCgWDwYRtZZGNaY2ZqX2R6a6O112NfkGN3uf3+iRq9AtqzFznJxc94Wr42Lp1q1paWlRaWhpva29v16OPPqpVq1bpk08+SdonFAopFAoltQeDwYwfnFRjxNp7Forclq0nsxuPU39Hjd7n9/okavQLasxs3J5yNXzMmzdPt9xyS0Lb9OnTNW/ePN1zzz1uHgoAAHhUr8PH6dOndfDgwfj9pqYm7dmzR4WFhSotLdWwYcMS+geDQRUXF+urX/1q5rMFAACe1+vwsWvXLk2bNi1+v/N6jZqaGr300kuuTQwAAPhTr8NHeXm5evMFmVTXeQAAgD9c/LYLAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKt6HT62bNmiWbNmKRwOKxAIaP369fFtjuNo8eLFmjBhgnJzcxUOh3X33Xfr6NGjbs4ZAAB4WK/Dx5kzZzRx4kStXr06aVtbW5saGxu1bNkyNTY26le/+pUOHDig2bNnuzJZAADgfYN6u0NVVZWqqqpSbisoKFB9fX1C209/+lNdc801Onz4sEpLS9ObJQAA8I1eh4/eam1tVSAQ0EUXXZRyeywWUywWi9+PRqOS/u8jHMdx0jpm536p9g8NNGmNmal0a7nQeG6P259Qo/f5vT6JGv2CGt0bvycCxpi0X40DgYDWrVunOXPmpNx+9uxZTZkyRePGjdPLL7+csk8kElFtbW1Se11dnXJyctKdGgAAsKitrU3V1dVqbW1Vfn5+t32zFj4cx9Htt9+uw4cPa/PmzV1OJNU7HyUlJTp27NgFJ98Vx3FUX1+viooKBYPBhG1lkY1pjZmpfZHpro7XXY1+QY3e5/f6JGr0C2rMXDQaVVFRUY/CR1Y+dnEcR9/+9rfV1NSkf//3f+92EqFQSKFQKKk9GAxm/OCkGiPWHshozEzmkq1x/XqidKJG7/N7fRI1+gU1ZjZuT7kePjqDx0cffaRNmzZp2LBhbh8CAAB4WK/Dx+nTp3Xw4MH4/aamJu3Zs0eFhYUKh8P6sz/7MzU2Nupf/uVf1N7erubmZklSYWGhBg8e7N7MAQCAJ/U6fOzatUvTpk2L31+0aJEkqaamRpFIRK+//rok6corr0zYb9OmTSovL09/pgAAwBd6HT7Ky8vV3TWqGVy/CgAA/gDw2y4AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsKrX4WPLli2aNWuWwuGwAoGA1q9fn7DdGKNIJKJwOKyhQ4eqvLxc77//vlvzBQAAHtfr8HHmzBlNnDhRq1evTrn9xz/+sVauXKnVq1dr586dKi4uVkVFhU6dOpXxZAEAgPcN6u0OVVVVqqqqSrnNGKNVq1bp8ccf12233SZJWrNmjS655BLV1dXp/vvvz2y2AADA83odPrrT1NSk5uZmVVZWxttCoZCmTp2qbdu2pQwfsVhMsVgsfj8ajUqSHMeR4zhpzaNzv1T7hwaatMbMVLq1XGg8t8ftT6jR+/xen0SNfkGN7o3fEwFjTNqvxoFAQOvWrdOcOXMkSdu2bdONN96oI0eOKBwOx/v9xV/8hQ4dOqSNGzcmjRGJRFRbW5vUXldXp5ycnHSnBgAALGpra1N1dbVaW1uVn5/fbV9X3/noFAgEEu4bY5LaOi1dulSLFi2K349GoyopKVFlZeUFJ98Vx3FUX1+viooKBYPBhG1lkeQAZMO+yHRXx+uuRr+gRu/ze30SNfoFNWau85OLnnA1fBQXF0uSmpubNWLEiHh7S0uLLrnkkpT7hEIhhUKhpPZgMJjxg5NqjFh76hCUbdl6MrvxOPV31Oh9fq9Poka/oMbMxu0pV//Ox9ixY1VcXKz6+vp427lz5/TOO+/ohhtucPNQAADAo3r9zsfp06d18ODB+P2mpibt2bNHhYWFKi0t1cKFC/XUU0/psssu02WXXaannnpKOTk5qq6udnXiAADAm3odPnbt2qVp06bF73der1FTU6OXXnpJP/jBD/T73/9eDz74oE6cOKFrr71Wb731lvLy8tybNQAA8Kxeh4/y8nJ19wWZQCCgSCSiSCSSybwAAIBP8dsuAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALDK9fDxxRdf6G/+5m80duxYDR06VF/5ylf0wx/+UB0dHW4fCgAAeNAgtwd85pln9Pzzz2vNmjUaP368du3apXvuuUcFBQV65JFH3D4cAADwGNfDx/bt23XrrbdqxowZkqQxY8bolVde0a5du9w+FAAA8CDXP3aZMmWK/u3f/k0HDhyQJL333nt699139a1vfcvtQwEAAA9y/Z2PxYsXq7W1VePGjdPAgQPV3t6uJ598UnfddVfK/rFYTLFYLH4/Go1KkhzHkeM4ac2hc79U+4cGmrTGzFS6tVxoPLfH7U+o0fv8Xp9EjX5Bje6N3xMBY4yrr8Zr167VY489pp/85CcaP3689uzZo4ULF2rlypWqqalJ6h+JRFRbW5vUXldXp5ycHDenBgAAsqStrU3V1dVqbW1Vfn5+t31dDx8lJSVasmSJ5s+fH2974okn9PLLL+vDDz9M6p/qnY+SkhIdO3bsgpPviuM4qq+vV0VFhYLBYMK2ssjGtMbM1L7IdFfH665Gv6BG7/N7fRI1+gU1Zi4ajaqoqKhH4cP1j13a2to0YEDipSQDBw7s8qu2oVBIoVAoqT0YDGb84KQaI9YeyGjMTOaSrXH9eqJ0okbv83t9EjX6BTVmNm5PuR4+Zs2apSeffFKlpaUaP368du/erZUrV+ree+91+1AAAMCDXA8fP/3pT7Vs2TI9+OCDamlpUTgc1v3336+//du/dftQAADAg1wPH3l5eVq1apVWrVrl9tAAAMAH+G0XAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFZlJXwcOXJEf/7nf65hw4YpJydHV155pRoaGrJxKAAA4DGD3B7wxIkTuvHGGzVt2jT967/+q4YPH66PP/5YF110kduHAgAAHuR6+HjmmWdUUlKiF198Md42ZswYtw8DAAA8yvXw8frrr2v69Om6/fbb9c4772jkyJF68MEHdd9996XsH4vFFIvF4vej0agkyXEcOY6T1hw690u1f2igSWvMTKVby4XGc3vc/oQavc/v9UnU6BfU6N74PREwxrj6ajxkyBBJ0qJFi3T77bfrN7/5jRYuXKif/exnuvvuu5P6RyIR1dbWJrXX1dUpJyfHzakBAIAsaWtrU3V1tVpbW5Wfn99tX9fDx+DBgzV58mRt27Yt3vbwww9r586d2r59e1L/VO98lJSU6NixYxecfFccx1F9fb0qKioUDAYTtpVFNqY1Zqb2Raa7Ol53NfoFNXqf3+uTqNEvqDFz0WhURUVFPQofrn/sMmLECH3ta19LaLviiiv02muvpewfCoUUCoWS2oPBYMYPTqoxYu2BjMbMZC7ZGtevJ0onavQ+v9cnUaNfUGNm4/aU61+1vfHGG7V///6EtgMHDmj06NFuHwoAAHiQ6+HjL//yL7Vjxw499dRTOnjwoOrq6vTCCy9o/vz5bh8KAAB4kOvh4+qrr9a6dev0yiuvqKysTD/60Y+0atUqzZ071+1DAQAAD3L9mg9JmjlzpmbOnJmNoQEAgMfx2y4AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsCrr4WPFihUKBAJauHBhtg8FAAA8IKvhY+fOnXrhhRf09a9/PZuHAQAAHpK18HH69GnNnTtXP//5z3XxxRdn6zAAAMBjBmVr4Pnz52vGjBm65ZZb9MQTT3TZLxaLKRaLxe9Ho1FJkuM4chwnrWN37pdq/9BAk9aYmUq3lguN5/a4/Qk1ep/f65Oo0S+o0b3xeyJgjHH91Xjt2rV68skntXPnTg0ZMkTl5eW68sortWrVqqS+kUhEtbW1Se11dXXKyclxe2oAACAL2traVF1drdbWVuXn53fb1/Xw8emnn2ry5Ml66623NHHiREnqNnykeuejpKREx44du+Dku+I4jurr61VRUaFgMJiwrSyyMa0x+5vQAKMfTe7Qsl0DFOsIdNlvX2S6xVm5q7t19Au/1+j3+iRq9AtqzFw0GlVRUVGPwofrH7s0NDSopaVFkyZNire1t7dry5YtWr16tWKxmAYOHBjfFgqFFAqFksYJBoMZPzipxoi1d/1C7UWxjkC3NfnhJHLjudDf+b1Gv9cnUaNfUGNm4/aU6+HjG9/4hvbu3ZvQds8992jcuHFavHhxQvAAAAB/eFwPH3l5eSorK0toy83N1bBhw5LaAQDAHx7+wikAALAqa1+1/bLNmzfbOAwAAPAA3vkAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYJXr4WPFihW6+uqrlZeXp+HDh2vOnDnav3+/24cBAAAe5Xr4eOeddzR//nzt2LFD9fX1+uKLL1RZWakzZ864fSgAAOBBg9we8M0330y4/+KLL2r48OFqaGjQTTfd5PbhAACAx7gePs7X2toqSSosLEy5PRaLKRaLxe9Ho1FJkuM4chwnrWN27pdq/9BAk9aY/U1ogEn4Z1fSfQz7g+7W0S/8XqPf65Oo0S+o0b3xeyJgjMnaq7ExRrfeeqtOnDihrVu3puwTiURUW1ub1F5XV6ecnJxsTQ0AALiora1N1dXVam1tVX5+frd9sxo+5s+frw0bNujdd9/VqFGjUvZJ9c5HSUmJjh07dsHJd8VxHNXX16uiokLBYDBhW1lkY1pj9jehAUY/mtyhZbsGKNYR6OvpuGpfZLqk7tfRL/xeo9/rk6jRL6gxc9FoVEVFRT0KH1n72OWhhx7S66+/ri1btnQZPCQpFAopFAoltQeDwYwfnFRjxNr99UId6wj4rqbz18yN50J/5/ca/V6fRI1+QY2ZjdtTrocPY4weeughrVu3Tps3b9bYsWPdPgQAAPAw18PH/PnzVVdXp3/6p39SXl6empubJUkFBQUaOnSo24cDAAAe4/rf+XjuuefU2tqq8vJyjRgxIn579dVX3T4UAADwoKx87AIAANAVftsFAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWDerrCQBuGrNkQ9r7fvL0DBdn4m89fZxDA41+fI1UFtmoWHtAkncf565qTlXj+bxac1/oq3O4LLLxguuYjeNmoreP1Zefq/ufnJmlWfUM73wAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALAqa+Hj2Wef1dixYzVkyBBNmjRJW7duzdahAACAh2QlfLz66qtauHChHn/8ce3evVt/8id/oqqqKh0+fDgbhwMAAB6SlfCxcuVKffe739X3vvc9XXHFFVq1apVKSkr03HPPZeNwAADAQwa5PeC5c+fU0NCgJUuWJLRXVlZq27ZtSf1jsZhisVj8fmtrqyTpd7/7nRzHSWsOjuOora1Nx48fVzAYTNg26IszaY3Z3wzqMGpr69AgZ4DaOwJ9PR1XHT9+XFL369iVTNa387g2pVNjf9DTxznV87QvHmc3dFVzT85Fr9bcyebztK/O4UHOmbT/m9pX69vbx+rLz9VszPnUqVOSJGPMhTsblx05csRIMv/xH/+R0P7kk0+ayy+/PKn/8uXLjSRu3Lhx48aNmw9un3766QWzguvvfHQKBBKTozEmqU2Sli5dqkWLFsXvd3R06He/+52GDRuWsn9PRKNRlZSU6NNPP1V+fn5aY/R31OgPfq/R7/VJ1OgX1Jg5Y4xOnTqlcDh8wb6uh4+ioiINHDhQzc3NCe0tLS265JJLkvqHQiGFQqGEtosuusiVueTn5/v2SdSJGv3B7zX6vT6JGv2CGjNTUFDQo36uX3A6ePBgTZo0SfX19Qnt9fX1uuGGG9w+HAAA8JisfOyyaNEizZs3T5MnT9b111+vF154QYcPH9YDDzyQjcMBAAAPyUr4uOOOO3T8+HH98Ic/1GeffaaysjK98cYbGj16dDYOlyQUCmn58uVJH+f4CTX6g99r9Ht9EjX6BTXaFTCmJ9+JAQAAcAe/7QIAAKwifAAAAKsIHwAAwCrCBwAAsMp34ePZZ5/V2LFjNWTIEE2aNElbt27t6ymltGLFCl199dXKy8vT8OHDNWfOHO3fvz+hz3e+8x0FAoGE23XXXZfQJxaL6aGHHlJRUZFyc3M1e/Zs/fd//3dCnxMnTmjevHkqKChQQUGB5s2bp5MnT2a7REUikaT5FxcXx7cbYxSJRBQOhzV06FCVl5fr/fff90x9kjRmzJikGgOBgObPny/Jm2u4ZcsWzZo1S+FwWIFAQOvXr0/YbnPdDh8+rFmzZik3N1dFRUV6+OGHde7cuazW6DiOFi9erAkTJig3N1fhcFh33323jh49mjBGeXl50treeeednqhRsvvc7KsaU52bgUBAP/nJT+J9+vM69uR1wrPnY+a/5tJ/rF271gSDQfPzn//cfPDBB+aRRx4xubm55tChQ309tSTTp083L774otm3b5/Zs2ePmTFjhiktLTWnT5+O96mpqTHf/OY3zWeffRa/HT9+PGGcBx54wIwcOdLU19ebxsZGM23aNDNx4kTzxRdfxPt885vfNGVlZWbbtm1m27ZtpqyszMycOTPrNS5fvtyMHz8+Yf4tLS3x7U8//bTJy8szr732mtm7d6+54447zIgRI0w0GvVEfcYY09LSklBffX29kWQ2bdpkjPHmGr7xxhvm8ccfN6+99pqRZNatW5ew3da6ffHFF6asrMxMmzbNNDY2mvr6ehMOh82CBQuyWuPJkyfNLbfcYl599VXz4Ycfmu3bt5trr73WTJo0KWGMqVOnmvvuuy9hbU+ePJnQp7/WaIy952Zf1vjl2j777DPzy1/+0gQCAfPxxx/H+/TndezJ64RXz0dfhY9rrrnGPPDAAwlt48aNM0uWLOmjGfVcS0uLkWTeeeedeFtNTY259dZbu9zn5MmTJhgMmrVr18bbjhw5YgYMGGDefPNNY4wxH3zwgZFkduzYEe+zfft2I8l8+OGH7hfyJcuXLzcTJ05Mua2jo8MUFxebp59+Ot529uxZU1BQYJ5//nljTP+vL5VHHnnEXHrppaajo8MY4/01PP8/6DbX7Y033jADBgwwR44cifd55ZVXTCgUMq2trVmrMZXf/OY3RlLC/8hMnTrVPPLII13u099rtPXc7E/reOutt5qbb745oc1L63j+64SXz0fffOxy7tw5NTQ0qLKyMqG9srJS27Zt66NZ9Vxra6skqbCwMKF98+bNGj58uC6//HLdd999amlpiW9raGiQ4zgJNYfDYZWVlcVr3r59uwoKCnTttdfG+1x33XUqKCiw8rh89NFHCofDGjt2rO6880799re/lSQ1NTWpubk5Ye6hUEhTp06Nz8sL9X3ZuXPn9PLLL+vee+9N+FFEr6/hl9lct+3bt6usrCzhR6qmT5+uWCymhoaGrNZ5vtbWVgUCgaTfnfrHf/xHFRUVafz48fqrv/qr+E+KS96o0cZzs69r7PT5559rw4YN+u53v5u0zSvreP7rhJfPx6z9qq1tx44dU3t7e9KP111yySVJP3LX3xhjtGjRIk2ZMkVlZWXx9qqqKt1+++0aPXq0mpqatGzZMt18881qaGhQKBRSc3OzBg8erIsvvjhhvC/X3NzcrOHDhycdc/jw4Vl/XK699lr9wz/8gy6//HJ9/vnneuKJJ3TDDTfo/fffjx871XodOnQoPvf+XN/51q9fr5MnT+o73/lOvM3ra3g+m+vW3NycdJyLL75YgwcPtlr32bNntWTJElVXVyf8GNfcuXM1duxYFRcXa9++fVq6dKnee++9+O9a9fcabT03+8s6rlmzRnl5ebrtttsS2r2yjqleJ7x8PvomfHT68v9xSv+3YOe39TcLFizQf/7nf+rdd99NaL/jjjvi/15WVqbJkydr9OjR2rBhQ9IJ9GXn15yqfhuPS1VVVfzfJ0yYoOuvv16XXnqp1qxZE7+wLZ316i/1ne8Xv/iFqqqqEv7PwOtr2BVb69bXdTuOozvvvFMdHR169tlnE7bdd9998X8vKyvTZZddpsmTJ6uxsVFXXXWVpP5do83nZl+voyT98pe/1Ny5czVkyJCEdq+sY1evE6mO7YXz0TcfuxQVFWngwIFJCaylpSUprfUnDz30kF5//XVt2rRJo0aN6rbviBEjNHr0aH300UeSpOLiYp07d04nTpxI6PflmouLi/X5558njfU///M/1h+X3NxcTZgwQR999FH8Wy/drZeX6jt06JDefvttfe973+u2n9fX0Oa6FRcXJx3nxIkTchzHSt2O4+jb3/62mpqaVF9ff8GfIL/qqqsUDAYT1ra/1/hl2Xpu9ocat27dqv3791/w/JT65zp29Trh6fOx11eJ9GPXXHON+f73v5/QdsUVV/TLC047OjrM/PnzTTgcNgcOHOjRPseOHTOhUMisWbPGGPP/LyR69dVX432OHj2a8kKiX//61/E+O3bs6JMLMs+ePWtGjhxpamtr4xdKPfPMM/HtsVgs5YVSXqhv+fLlpri42DiO020/r62hurjg1Ma6dV7gdvTo0XiftWvXWrlQ8dy5c2bOnDlm/PjxCd/Q6s7evXsTLgbs7zWeL1vPzf5QY01NTdK3lbrSn9bxQq8TXj4ffRU+Or9q+4tf/MJ88MEHZuHChSY3N9d88sknfT21JN///vdNQUGB2bx5c8JXvNra2owxxpw6dco8+uijZtu2baapqcls2rTJXH/99WbkyJFJX6EaNWqUefvtt01jY6O5+eabU36F6utf/7rZvn272b59u5kwYYKVr6I++uijZvPmzea3v/2t2bFjh5k5c6bJy8uLr8fTTz9tCgoKzK9+9Suzd+9ec9ddd6X8ilh/ra9Te3u7KS0tNYsXL05o9+oanjp1yuzevdvs3r3bSDIrV640u3fvjn/Tw9a6dX617xvf+IZpbGw0b7/9thk1apQrX9HsrkbHcczs2bPNqFGjzJ49exLOz1gsZowx5uDBg6a2ttbs3LnTNDU1mQ0bNphx48aZP/7jP/ZEjTafm31VY6fW1laTk5NjnnvuuaT9+/s6Xuh1whjvno++Ch/GGPP3f//3ZvTo0Wbw4MHmqquuSvjqan8iKeXtxRdfNMYY09bWZiorK80f/dEfmWAwaEpLS01NTY05fPhwwji///3vzYIFC0xhYaEZOnSomTlzZlKf48ePm7lz55q8vDyTl5dn5s6da06cOJH1Gju/bx4MBk04HDa33Xabef/99+PbOzo64u8YhEIhc9NNN5m9e/d6pr5OGzduNJLM/v37E9q9uoabNm1K+dysqakxxthdt0OHDpkZM2aYoUOHmsLCQrNgwQJz9uzZrNbY1NTU5fnZ+fdbDh8+bG666SZTWFhoBg8ebC699FLz8MMPJ/2djP5ao+3nZl/U2OlnP/uZGTp0aNLf7jCm/6/jhV4njPHu+Rj4fwUCAABY4ZsLTgEAgDcQPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFj1v0li2yupxcxBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "# get length of all the messages in the train set\n",
    "seq_len = [len(str(i).split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janinedevera/opt/miniconda3/envs/tad-project/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 2\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janinedevera/opt/miniconda3/envs/tad-project/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5)          # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [1.0625     0.94444444]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_labels),\n",
    "                                        y = train_labels                                                    \n",
    "                                    )\n",
    "\n",
    "class_weights\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 200 batches.\n",
    "    # if step % 200 == 0 and not step == 0:\n",
    "    #   print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  #print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 200 batches.\n",
    "    # if step % 200 == 0 and not step == 0:\n",
    "      \n",
    "    #   # Calculate elapsed time in minutes.\n",
    "    #   #elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "    #   # Report progress.\n",
    "    #   print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 20\n",
      "\n",
      "Training Loss: 0.700\n",
      "Validation Loss: 0.699\n",
      "\n",
      " Epoch 2 / 20\n",
      "\n",
      "Training Loss: 0.696\n",
      "Validation Loss: 0.701\n",
      "\n",
      " Epoch 3 / 20\n",
      "\n",
      "Training Loss: 0.687\n",
      "Validation Loss: 0.702\n",
      "\n",
      " Epoch 4 / 20\n",
      "\n",
      "Training Loss: 0.701\n",
      "Validation Loss: 0.701\n",
      "\n",
      " Epoch 5 / 20\n",
      "\n",
      "Training Loss: 0.700\n",
      "Validation Loss: 0.694\n",
      "\n",
      " Epoch 6 / 20\n",
      "\n",
      "Training Loss: 0.692\n",
      "Validation Loss: 0.686\n",
      "\n",
      " Epoch 7 / 20\n",
      "\n",
      "Training Loss: 0.686\n",
      "Validation Loss: 0.687\n",
      "\n",
      " Epoch 8 / 20\n",
      "\n",
      "Training Loss: 0.683\n",
      "Validation Loss: 0.687\n",
      "\n",
      " Epoch 9 / 20\n",
      "\n",
      "Training Loss: 0.682\n",
      "Validation Loss: 0.684\n",
      "\n",
      " Epoch 10 / 20\n",
      "\n",
      "Training Loss: 0.676\n",
      "Validation Loss: 0.685\n",
      "\n",
      " Epoch 11 / 20\n",
      "\n",
      "Training Loss: 0.685\n",
      "Validation Loss: 0.687\n",
      "\n",
      " Epoch 12 / 20\n",
      "\n",
      "Training Loss: 0.686\n",
      "Validation Loss: 0.684\n",
      "\n",
      " Epoch 13 / 20\n",
      "\n",
      "Training Loss: 0.690\n",
      "Validation Loss: 0.682\n",
      "\n",
      " Epoch 14 / 20\n",
      "\n",
      "Training Loss: 0.683\n",
      "Validation Loss: 0.681\n",
      "\n",
      " Epoch 15 / 20\n",
      "\n",
      "Training Loss: 0.680\n",
      "Validation Loss: 0.682\n",
      "\n",
      " Epoch 16 / 20\n",
      "\n",
      "Training Loss: 0.681\n",
      "Validation Loss: 0.680\n",
      "\n",
      " Epoch 17 / 20\n",
      "\n",
      "Training Loss: 0.687\n",
      "Validation Loss: 0.677\n",
      "\n",
      " Epoch 18 / 20\n",
      "\n",
      "Training Loss: 0.687\n",
      "Validation Loss: 0.678\n",
      "\n",
      " Epoch 19 / 20\n",
      "\n",
      "Training Loss: 0.674\n",
      "Validation Loss: 0.672\n",
      "\n",
      " Epoch 20 / 20\n",
      "\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 0.673\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.73      0.72      0.72        11\n",
      "weighted avg       0.73      0.73      0.72        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    39\n",
       "0    34\n",
       "Name: label.132, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label.132'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 73 entries, 1 to 181\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Reference                     73 non-null     object\n",
      " 1   Feedback date                 73 non-null     object\n",
      " 2   User type                     65 non-null     object\n",
      " 3   Scope                         2 non-null      object\n",
      " 4   Organisation name             65 non-null     object\n",
      " 5   Transparency register number  52 non-null     object\n",
      " 6   Organisation size             65 non-null     object\n",
      " 7   label_132                     73 non-null     object\n",
      " 8   label_134                     73 non-null     object\n",
      " 9   submit                        73 non-null     int64 \n",
      " 10  file_name                     73 non-null     object\n",
      " 11  language                      73 non-null     object\n",
      " 12  text                          73 non-null     object\n",
      " 13  text_clean                    73 non-null     object\n",
      " 14  label.132                     73 non-null     int64 \n",
      " 15  label.134                     73 non-null     int64 \n",
      "dtypes: int64(3), object(13)\n",
      "memory usage: 9.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for tf-idf word embeddings:\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tad-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cab4409ce5d224ee9075dc374e4bd34bc4b9571e804fbf24e5d7f1c9b19a09d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
