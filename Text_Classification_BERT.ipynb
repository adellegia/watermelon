{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13i7KQ9t-CV8"
      },
      "source": [
        "# Classification of Unstructured Documents \n",
        "## *Transfer Learning with BERT*\n",
        "### GRAD-E1394 Deep Learning\n",
        "\n",
        "---\n",
        "\n",
        "Authors:\n",
        "*   Ma. Adelle Gia Arbo, m.arbo@students.hertie-school.org\n",
        "*   Janine De Vera, j.devera@students.hertie-school.org\n",
        "*   Lorenzo Gini, l.gini@students.hertie-school.org\n",
        "*   Lukas Warode, l.warode@students.hertie-school.org | lukas.warode@gmx.de\n",
        "\n",
        "---\n",
        "\n",
        "This tutorial demonstrates the pipeline for classifying unstructured documents, particularly those in PDF format. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNv0ANr5WcD_"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "\n",
        "*   [Memo](#memo)\n",
        "*   [Overview](#overview)\n",
        "*   [Background & Prerequisites](#background-and-prereqs)\n",
        "*   [Software Requirements](#software-requirements)\n",
        "*   [Data Description](#data-description)\n",
        "*   [Methodology](#methodology)\n",
        "*   [Results & Discussion](#results-and-discussion)\n",
        "*   [References](#references)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH81wjfsJsv1"
      },
      "source": [
        "<a name=\"memo\"></a>\n",
        "# Memo\n",
        "\n",
        "Write a memo for the leadership explaining in layman's terms why this topic is relevant for public policy. Discuss relevant research works, real-world examples of successful applications, and organizations and governments that apply such approaches for policy making. \n",
        "\n",
        "\n",
        "### *Sketch Lukas (not done)*\n",
        "\n",
        "#### Main Point / Take Away (Executive Summary???)\n",
        "\n",
        "#### Background \n",
        "\n",
        "Companies as well as public and political institutions are able and ofent required to access loads of information nowadays. In doing that, they often face the problem of unstructured information, especially when dealing with text data. Data in textual form is the most common type of unstructured, unfortunately, it is also representing the most fundamental type of documents with respect to policymakers and public institutions: Legal documents, bills and policy papers are just some examples of common text sources, which are part of the daily business in the political world. Unstructured text data entails a variety of different problems when it comes actually gaining quantitative analytical insights from them. Computers commonly have difficulties understanding textual data. Analytical and technical competences are also scarce: Only 18% of companies are able to use unstructured data, while most organizations are make their (data-driven) decisions on the basis of only 10 to 20% of their available data source. The situation for public institutions is worsend by the fact that most of the modern text data analysis frameworks and models are dominated by different industry players, while being designed and trained according to the industry-specific needs, which do not transfer to the needs of the mentioned political text sources. The EU Commission (or directly mention DMA?) …\n",
        "\n",
        "This motivates the necessity of implementing …\n",
        "\n",
        "#### Evidence (Sktech our technical solution?)\n",
        "- Text Classification Pipepline + BERT Model(ling)\n",
        "\n",
        "- Results??\n",
        "\n",
        "\n",
        "#### Conclusion and Implementation\n",
        "\n",
        "- Results??\n",
        "\n",
        "- Being specific about implementation and actual usage (maybe even specify DMA context a bit more and say who and what stakeholders/institutions are taking what position in context)\n",
        "\n",
        "*Open points*\n",
        "\n",
        "- Include practicality and gained efficiency\n",
        "- Normative perspective: \"Technical\" objectivity (but one needs to be careful for potential biases)\n",
        "\n",
        "\\\n",
        "- Directly mention DMA at beginning?\n",
        "- How structured should the memo be?\n",
        "\n",
        "\\\n",
        "- Sources need to be added for numbers of slides (e.g. 18% of companies blabla)\n",
        "\n",
        "\n",
        "*Structure*\n",
        "![](https://mitcommlab.mit.edu/broad/wp-content/uploads/sites/5/2017/12/policy-memo-struct-700x843.png)\n",
        "\n",
        "![](https://www.bu.edu/sph/files/2014/06/Policy-Memo-Organization.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2u40fYe3EOL"
      },
      "source": [
        "<a name=\"overview\"></a>\n",
        "# Overview\n",
        "\n",
        "Over 80% of all data is *unstructured*. Most of the information we consume come in a format that is not organized in a pre-defined manner (e.g. tables) or with a specific data model in mind (e.g. matrices). \n",
        "\n",
        "<u>Text</u> is the most common type of unstructured data and it comes in a variety of forms like blogs, news articles, social media content, as well as official documents. This lack of structure that can be readily understood by machines is what makes it difficult to maximize text as a data source. Algorithms that efficiently and accurately process text would have a variety of applications in organisations, especially public institutions that have access to different types of documents. \n",
        "\n",
        "In this tutorial we demonstrate one such application in the context of the European Commission (EC). Whenever new legislation is proposed, the EC opens **public consultations** where various stakeholders (e.g. businesses, academia, law firms, associations, private individuals) submit documents that detail their views on the proposal. The EC receives anywhere between 10,000 to 4 million of these public consultation documents annually. Using machine learning and deep learning methods to process these documents would streamline the Commission's review of stakeholder comments, which will consequently allow them to integrate more information into their policymaking process. \n",
        "\n",
        "The main goal of this tutorial is to walk you through the steps of building a <u>document classifier</u> using a deep learning model called **Bidirectional Encoder Representations from Transformers (BERT)**. By the end of this tutorial you will understand how to:  \n",
        "\n",
        "> 1. Extract, clean, and pre-process information from PDF documents\n",
        "> 2. Use the pre-processed text as input to machine learning/deep learning models\n",
        "> 3. Build a text/document classifier with BERT \n",
        "> 4. Compare BERT with text classifiers built using other models\n",
        "\n",
        "We will then apply these learnings to accomplish a research objective: \n",
        "\n",
        " > Classify public consultation documents of the recently enacted **Digital Markets Act** according to whether a stakeholder **agrees or disagrees** with the DMA proposal. \n",
        "\n",
        "The Digital Markets Act is a regulation in the European Union which came into force this 2022. It aims to promote fair competition within the digital market by defining rules for “gatekeepers” or large online platforms. Majority of the public consultation documents submitted for the DMA are from companies and business associations who will likely be affected by the law."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQgijl46pYzn"
      },
      "source": [
        "<a name=\"background-and-prereqs\"></a>\n",
        "# Background & Prerequisites\n",
        "\n",
        "For this tutorial, you would need to be familiar with object oriented programming, common python libraries such as *numpy* and *pandas*, and libraries used for model building, such as *scikit-learn* and *pytorch*. Working knowledge of common language processing concepts (e.g. stemming, lemmatization, TF-IDF, embeddings) would also be useful. \n",
        "\n",
        "Important concepts that need to be explained briefly:  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7BpQklEEIFDD"
      },
      "source": [
        "## Reading materials\n",
        "\n",
        "For detailed explanations of the topics covered in this tutorial, below is a list helpful references.\n",
        "\n",
        "**Basics of natural language processing models:**\n",
        "* Vajjala, S., Majumder, B., Gupta, A., & Surana, H. (2020). Practical natural language processing: a comprehensive guide to building real-world NLP systems. O'Reilly Media.\n",
        "\n",
        "\n",
        "**BERT:**\n",
        "* Horev, R. (2018). BERT Explained: State of the art language model for NLP. Towards Data Science, 10.\n",
        "* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSRCNgYzUwaf"
      },
      "source": [
        "<a name=\"software-requirements\"></a>\n",
        "# Software Requirements\n",
        "To install software requirements and dependencies, please create a new environment using the *environment.yml* file which accompanies this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!conda env create -f environment.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xVzk4V7qUu2R"
      },
      "outputs": [],
      "source": [
        "# Data visualization\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parsing and pre-processing\n",
        "from glob import glob\n",
        "import os \n",
        "import re\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "from langdetect import detect, DetectorFactory\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from string import punctuation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic and XGboost\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/janinedevera/opt/miniconda3/envs/watermelon/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# LSTM \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BERT models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import yaml\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# specify GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXoiLncsU3pe"
      },
      "source": [
        "<a name=\"data-description\"></a>\n",
        "# Data Description\n",
        "\n",
        "As mentioned in the [Overview](#overview), the methods discussed in this tutorial will be applied to public consultation documents of the **Digital Markets Act (DMA)**. The open public consultation for DMA received **188 responses**. In addition to document submissions, each respondent answered an accompanying survey. They were asked a series of questions about what they think about the law. \n",
        "\n",
        "To build our document classifier we need the raw **text** from the public consultation submissions, and a corresponding **label** for each document which indicates whether or not the author/s agree or disagree with the DMA proposal. \n",
        "\n",
        "**Text:**\n",
        "The submissions come in the form of **pdf files**. These documents need to be parsed in order to extract raw text. \n",
        "\n",
        "**Labels:**\n",
        "The labels are extracted from the **survey**, specifically from the question: \n",
        "\n",
        "*\"Do you consider that there is a need for the Commission to be able to intervene in gatekeeper scenarios to prevent/address structural competition problems?*\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoF-BxSM5Jkc"
      },
      "source": [
        "## Data Download\n",
        "\n",
        "The pdf documents and the survey used to generate labels can be downloaded from the <a href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12416-New-competition-tool/public-consultation_en\">DMA consultation page</a>. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSt6h_Q-oqjK"
      },
      "source": [
        "## Data Preprocessing\n",
        "Additionally, you can include any data preprocessing steps and exploratory data analyses (e.g. visualize data distributions, impute missing values, etc.) in this section to allow the users to better understand the dataset. \n",
        "\n",
        "In this section, you might also want to describe the different input and output variables, the train/val/test splits, and any data transformations.\n",
        "\n",
        "(Describe processing of labels here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert cleaning of DMA excel file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aBJ5aLZosk-"
      },
      "outputs": [],
      "source": [
        "# Insert data pre-processing and exploratory data analysis\n",
        "# code here. Feel free to break this up into several code\n",
        "# cells, interleaved with explanatory text. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9Iuu2GU52Z"
      },
      "source": [
        "<a name=\"methodology\"></a>\n",
        "# Methodology\n",
        "\n",
        "This section of the tutorial is a step-by-step walkthrough of text classification pipeline, using DMA public consultation documents as described above. Below is an outline of this section: \n",
        "\n",
        "<ol type=\"A\">\n",
        "  <li>Data Preparation </li>\n",
        "  <li>Text Representation</li>\n",
        "  <li>Model Training (with hyperparameter tuning)</li>\n",
        "  <ol>\n",
        "    <li> Training baseline models (logistic, XGBoost)\n",
        "    <li> Training a DL classifier (LSTM)\n",
        "    <li> Transfer learning with BERT and other variants\n",
        "  </ol>\n",
        "  <li> Model Evaluation\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWXsiZ5freTG"
      },
      "source": [
        "## A. Data Preparation \n",
        "In this section of the tutorial, we will (1) parse PDF submissions from the Digital Markets Act public consultation and (2) pre-process raw text to keep only the most relevant information. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A.1 Parsing PDFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a list of file paths of all pdf submissions: `pdf_list`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_dir = \"../data/reports/\"\n",
        "pdf_list = glob(os.path.join(pdf_dir, \"*.pdf\"))\n",
        "pdf_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each of the downloaded public consultation documents has a unique alpha-numeric ID. For example: the document ID for **\"F549293-Statement_on_the_New_Competition_Tool\"** is *F549293*.\n",
        "\n",
        "We use a regular expression to extract this from the file paths and save it in a list called `pdf_id`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_id = [re.search('[F][0-9]{6}', i)[0] for i in pdf_list]\n",
        "pdf_id = list(set(pdf_id))\n",
        "len(pdf_id) # no. of unique pdf submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PDF (Portable Document Format) documents are hard to work with because this format was not designed as a data input. Instead, the PDF contains a set of instructions that describe how characters or objects are positioned on a page. \n",
        "\n",
        "Python has text analytics libraries that convert PDFs into the required encoding format. There are several of these PDF libraries, however, they sometimes yield varying results. Here, we demonstrate one such library, `pdfminer`. We have also tried other libraries like `pdfplumber`, so feel free to also experiment on which PDF parser works best for your corpus. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a dataframe `df_text` which contains information for each document - the reference number (unique ID), file name, complete text of the document, and the language the document was written in. The full text of the document is parsed using the PDF library and the language of the text is determined by a language detection library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_text = pd.DataFrame(columns = ['Reference', 'file_name', 'text', 'lang'])\n",
        "\n",
        "for pdf_file in pdf_list:\n",
        "    Reference = re.search('[F][0-9]{6}', pdf_file)[0]\n",
        "    file_name = re.search('[F][0-9]{6}(.*)[\\\\>.]', pdf_file)[0]\n",
        "    text = extract_text(pdf_file)\n",
        "    lang = detect(text)\n",
        "    row = pd.DataFrame({'Reference': Reference,'file_name': file_name,\n",
        "                        'text': text, 'lang': lang}, index=[0])\n",
        "    df_text = pd.concat([row,df_text.loc[:]]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output of the parsing step looks likes this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "df_text.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert merging step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A.2 Cleaning and Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After parsing PDFs, we need to further process the raw text to ensure that most of the information we feed into our model/s is relevant to the task at hand. For instance, stopwords like \"the\", \"this\", \"and\" will not give us any indication of whether a stakeholder agrees with a law, so we can remove these words. \n",
        "\n",
        "The pre-processing steps that we apply for this tutorial are the following: \n",
        "\n",
        "1. Removal of stopwords, punctuations, and numeric characters\n",
        "2. Stemming \n",
        "3. Lemmatization\n",
        "4. Language detection\n",
        "5. Coreference resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is what the raw text looks like before processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eng.text[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Removal of stopwords, punctuations, numeric characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_corpus(texts):\n",
        "    eng_stopwords = set(stopwords.words(\"english\"))\n",
        "    def remove_stops_digits(tokens):\n",
        "        token_list =  [token.lower() for token in tokens if token not in eng_stopwords and token not in punctuation and token.isdigit() == False]\n",
        "        processed_text = ' '.join(token_list)\n",
        "        return processed_text\n",
        "    return [remove_stops_digits(word_tokenize(text)) for text in texts]\n",
        "\n",
        "df_eng['text_clean'] = preprocess_corpus(df_eng['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stemming and lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stem_lemmatize(text):\n",
        "    stemmed = [stemmer.stem(token) for token in word_tokenize(text)]\n",
        "    lemmatized = [lemmatizer.lemmatize(token) for token in stemmed]\n",
        "    processed_text = ' '.join(lemmatized)\n",
        "    return processed_text\n",
        "\n",
        "df_eng['text_clean'] = [stem_lemmatize(text) for text in df_eng['text_clean']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Coreference resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# installing neuralcoref from source\n",
        "!git clone https://github.com/huggingface/neuralcoref.git\n",
        "!cd neuralcoref\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "import neuralcoref\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm') \n",
        "neuralcoref.add_to_pipe(nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def coref_res(texts):\n",
        "    doc = nlp(texts)\n",
        "    clean = doc._.coref_resolved\n",
        "    return clean\n",
        "\n",
        "df_eng['text_clean'] = [coref_res(text) for text in df_eng['text_clean']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8L28axZ4NVj"
      },
      "source": [
        "## B. Text Representation\n",
        "Since this step is built inside BERT and other DL models, we can use what Lorenzo has done for the baseline models (TF-IDF & embeddings) to illustrate how text representation works. \n",
        "\n",
        "In the BERT section explain how the architecture processes text to create embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. Model Training (with hyperparameter tuning)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load and split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_json(r\"./data/df_final_document.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "df['label.132'] = le.fit_transform(df['label_132'])\n",
        "df['label.134'] = le.fit_transform(df['label_134'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C.1 Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "dfm = vectorizer.fit_transform(df['text_clean'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 62.79 \n",
            " Precision: 0.625 \n",
            " Recall: 0.962 \n",
            " F1: 0.758\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=0).fit(train_text, train_labels)\n",
        "\n",
        "y_pred = clf.predict(test_text)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, y_pred) *100.0\n",
        "precision = precision_score(test_labels, y_pred, average='binary')\n",
        "recall = recall_score(test_labels, y_pred, average='binary')\n",
        "f_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f' Accuracy: {accuracy:.2f} \\n Precision: {precision:.3f} \\n Recall: {recall:.3f} \\n F1: {f_score:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
            "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
            "              early_stopping_rounds=None, enable_categorical=False,\n",
            "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
            "              grow_policy='depthwise', importance_type=None,\n",
            "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
            "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
            "              max_depth=1000, max_leaves=0, min_child_weight=1, missing=nan,\n",
            "              monotone_constraints='()', n_estimators=1000, n_jobs=0,\n",
            "              num_parallel_tree=1, predictor='auto', random_state=0, ...)\n",
            " Accuracy: 67.44 \n",
            " Precision: 0.688 \n",
            " Recall: 0.846 \n",
            " F1: 0.759\n"
          ]
        }
      ],
      "source": [
        "bst = XGBClassifier(n_estimators=1000, max_depth=1000, learning_rate=0.1, objective='binary:logistic')\n",
        "\n",
        "bst.fit(train_text, train_labels)\n",
        "\n",
        "print(bst)\n",
        "\n",
        "y_pred = bst.predict(test_text)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, y_pred) * 100.0\n",
        "precision = precision_score(test_labels, y_pred, average='binary')\n",
        "recall = recall_score(test_labels, y_pred, average='binary')\n",
        "f_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f' Accuracy: {accuracy:.2f} \\n Precision: {precision:.3f} \\n Recall: {recall:.3f} \\n F1: {f_score:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C.2 Long Short-Term Memory Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After splitting the data into training and test set, build the corpus vocabulary by tokenizing all texts and assigning each word to a unique index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def tokenize(datasets):\n",
        "    for dataset in datasets:\n",
        "        for text in dataset:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(tokenize([train_text, test_text]), min_freq=1, specials=[\"<UNK>\"])\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7332, 1493, 719, 6370, 1]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example\n",
        "tokens = tokenizer(\"This is an example.\")\n",
        "index = vocab(tokens)\n",
        "index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the vocabulary is built, we create batches of text sequences and map the tokens to indices. We also pad the sequence of words so all are of the same length. This returns a tensor of the sequence length and batch size. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_classes = [\"0\", \"1\"]\n",
        "max_words = 100\n",
        "\n",
        "def vectorize_batch(batch):\n",
        "    Y, X = list(zip(*batch))\n",
        "    X = [vocab(tokenizer(text)) for text in X] # map tokes to index using vocab\n",
        "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] # pad sequences\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.int32), torch.tensor(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=100, collate_fn=vectorize_batch, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=100, collate_fn=vectorize_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 100]) torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "for X, Y in train_loader:\n",
        "    print(X.shape, Y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create LSTM classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define hyperparameters\n",
        "embed_len = 100\n",
        "hidden_dim = 60\n",
        "n_layers = 2\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embed_len = embed_len\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len)\n",
        "        self.lstm = nn.LSTM(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, len(target_classes))\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        hidden, carry = torch.randn(n_layers, len(X_batch), hidden_dim), torch.randn(n_layers, len(X_batch), hidden_dim)\n",
        "        output, (hidden, carry) = self.lstm(embeddings, (hidden, carry))\n",
        "        return self.linear(output[:,-1])\n",
        "\n",
        "    def init_hidden(self):\n",
        "      return (\n",
        "               torch.zeros(n_layers, 1, self.hidden_dim, device=device),\n",
        "               torch.zeros(n_layers, 1, self.hidden_dim, device=device)\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (embedding_layer): Embedding(14499, 100)\n",
              "  (lstm): LSTM(100, 60, num_layers=2, batch_first=True)\n",
              "  (linear): Linear(in_features=60, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm_classifier = LSTMClassifier()\n",
        "lstm_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer : Embedding(14499, 100)\n",
            "Parameters : \n",
            "torch.Size([14499, 100])\n",
            "\n",
            "Layer : LSTM(100, 60, num_layers=2, batch_first=True)\n",
            "Parameters : \n",
            "torch.Size([240, 100])\n",
            "torch.Size([240, 60])\n",
            "torch.Size([240])\n",
            "torch.Size([240])\n",
            "torch.Size([240, 60])\n",
            "torch.Size([240, 60])\n",
            "torch.Size([240])\n",
            "torch.Size([240])\n",
            "\n",
            "Layer : Linear(in_features=60, out_features=2, bias=True)\n",
            "Parameters : \n",
            "torch.Size([2, 60])\n",
            "torch.Size([2])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for layer in lstm_classifier.children():\n",
        "    print(\"Layer : {}\".format(layer))\n",
        "    print(\"Parameters : \")\n",
        "    for param in layer.parameters():\n",
        "        print(param.shape)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1024, 2])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = lstm_classifier(torch.randint(0, len(vocab), (1024, max_words)))\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, loss_fn, val_loader):\n",
        "    with torch.no_grad():\n",
        "        Y_shuffled, Y_preds, losses = [],[],[]\n",
        "        for X, Y in val_loader:\n",
        "            preds = model(X)\n",
        "            loss = loss_fn(preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            Y_shuffled.append(Y)\n",
        "            Y_preds.append(preds.argmax(dim=-1))\n",
        "\n",
        "        Y_shuffled = torch.cat(Y_shuffled)\n",
        "        Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
        "\n",
        "def train(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
        "    for i in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for X, Y in tqdm(train_loader):\n",
        "            Y_preds = model(X)\n",
        "\n",
        "            loss = loss_fn(Y_preds, Y) \n",
        "            losses.append(loss.item())\n",
        "\n",
        "            ## back propagation\n",
        "            optimizer.zero_grad() \n",
        "            loss.backward() \n",
        "            optimizer.step() \n",
        "\n",
        "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        evaluate(model, loss_fn, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.697\n",
            "Valid Loss : 0.693\n",
            "Valid Acc  : 0.512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.690\n",
            "Valid Loss : 0.690\n",
            "Valid Acc  : 0.535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.682\n",
            "Valid Loss : 0.686\n",
            "Valid Acc  : 0.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.675\n",
            "Valid Loss : 0.683\n",
            "Valid Acc  : 0.605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.668\n",
            "Valid Loss : 0.679\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.660\n",
            "Valid Loss : 0.676\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.651\n",
            "Valid Loss : 0.673\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.642\n",
            "Valid Loss : 0.669\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.632\n",
            "Valid Loss : 0.666\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.621\n",
            "Valid Loss : 0.662\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.609\n",
            "Valid Loss : 0.659\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.595\n",
            "Valid Loss : 0.656\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.581\n",
            "Valid Loss : 0.653\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.564\n",
            "Valid Loss : 0.651\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.547\n",
            "Valid Loss : 0.651\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.528\n",
            "Valid Loss : 0.652\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.508\n",
            "Valid Loss : 0.655\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.487\n",
            "Valid Loss : 0.660\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.463\n",
            "Valid Loss : 0.665\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.437\n",
            "Valid Loss : 0.671\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 1e-3\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "lstm_classifier = LSTMClassifier()\n",
        "optimizer = Adam(lstm_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "train(lstm_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C.3 Transfer Learning with BERT and Other Variants"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Bidirectional Encoder Representations from Transformers** or **BERT** follows the Transformer architecture but it only uses the encoder part. Each transformer encoder consists of two sub-layers: self-attention and feed-forward. The key feature of BERT is its bidirectionality as it learns information from both left and right side of a token’s context. This allows for parallel processing, store the position of the input, and make lookup easy. \n",
        "\n",
        "\n",
        "BERT is trained from BookCorpus (800M words) and English Wikipedia (2.5B words). In a nutshell, BERT reads the input sequence and generates meaningful text representations, which it feeds into the encoder. This can then be augmented with additional neural network layers to fit a classification task. BERT has three embedding layers: token embedding layer, segment embedding layer, and position embedding layer. The element-wise sum of these three layers gives the final input representation.\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"./img/bert_embeddings.png\" width=\"250\" height=\"320\">\n",
        "</p>\n",
        "\n",
        "For NLP related task, the best practice is to use pre-trained models first, and then fine-tune them. This is called **transfer learning**, a technique where a deep learning model trained from a very large dataset is used as “off-the-shelf” to perform similar tasks on another dataset. There are 3 different fine-tuning techniques:\n",
        "> 1. Train the entire architecture which updates all pre-trained weights based on the new dataset\n",
        "> 2. Train the pretrained model partially and freeze the weights of the initial layer and retrain only on the higher levels\n",
        "> 3. Freeze entire architecture and attach a few NN layers to train the new model.\n",
        "\n",
        "In this tutorial, we will implement transfer model using a pre-trained BERT model. After collecting, preparing, and pre-processing the unstructured documents, we split the dataset into training, validation, and testing. We then implement transfer learning using the bert-base-uncased model with 12 encoder transformer layers trained on lower-case English texts. We use the wordpiece embeddings from BERT as inputs to our text classification task.\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"./img/bert_pipeline.png\" width=\"700\" height=\"320\">\n",
        "<p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split data into train, test, validation sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text_clean'], df['label.132'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label.132'])\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# bert-base-uncased\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', return_dict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# legal-bert-base-uncased\n",
        "bert = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", return_dict=False)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", return_dict=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Tokenize the Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert lists to tensors\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "num_workers = 2\n",
        "\n",
        "# dataLoader for train set\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_dataloader = DataLoader(train_data, num_workers=num_workers, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_dataloader = DataLoader(val_data, num_workers=num_workers, shuffle=True, batch_size=batch_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### BERT Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      self.relu =  nn.ReLU()\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# method to freeze all the parameters if freeze = T\n",
        "def set_parameter_requires_grad(model, freeze):\n",
        "    if freeze:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# freeze all parameters\n",
        "set_parameter_requires_grad(model=bert, freeze=True)\n",
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-5) # learning rate\n",
        "\n",
        "# loss function\n",
        "criterion  = nn.NLLLoss() \n",
        "\n",
        "# no. of training epochs\n",
        "epochs = 20"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Fine-tuning BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to train the model\n",
        "def train(model, dataloader, criterion, optimizer):\n",
        "  \n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  running_total_correct = 0.0\n",
        "  total_preds=[]\n",
        "  \n",
        "  for i, inputs in enumerate((dataloader)):\n",
        "    \n",
        "    # push to gpu\n",
        "    inputs = [r.to(device) for r in inputs]\n",
        "    sent_id, mask, labels = inputs\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    model.zero_grad()        \n",
        "\n",
        "    # forward + backward + optimize \n",
        "    preds = model(sent_id, mask)\n",
        "    loss = criterion(preds, labels)\n",
        "    total_loss = total_loss + loss.item()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) #prevent exploding gradient problem\n",
        "    optimizer.step()\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # epoch loss and accuracy\n",
        "  epoch_loss = total_loss / len(dataloader)\n",
        "  # reshape from (no. of batches, size of batch, no. of classes) to (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  print(f\"Train Loss: {epoch_loss:.2f}\")\n",
        "\n",
        "  return epoch_loss, total_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate(model, dataloader, criterion):\n",
        "  \n",
        "  model.eval()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  total_preds = []\n",
        "\n",
        "  for i, inputs in enumerate((dataloader)):\n",
        "    \n",
        "    # push to gpu\n",
        "    inputs = [t.to(device) for t in inputs]\n",
        "    sent_id, mask, labels = inputs\n",
        "\n",
        "    with torch.no_grad():\n",
        "      preds = model(sent_id, mask)\n",
        "      loss = criterion(preds,labels)\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # epoch loss and accuracy\n",
        "  epoch_loss = total_loss / len(dataloader) \n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  print(f\"Validation Loss: {epoch_loss:.2f}\")\n",
        "\n",
        "  return epoch_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.70\n",
            "\n",
            " Epoch 2 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 3 / 20\n",
            "Train Loss: 0.68\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 4 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 5 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.67\n",
            "\n",
            " Epoch 6 / 20\n",
            "Train Loss: 0.69\n",
            "Validation Loss: 0.66\n",
            "\n",
            " Epoch 7 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 8 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.64\n",
            "\n",
            " Epoch 9 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.67\n",
            "\n",
            " Epoch 10 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.66\n",
            "\n",
            " Epoch 11 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.65\n",
            "\n",
            " Epoch 12 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.65\n",
            "\n",
            " Epoch 13 / 20\n",
            "Train Loss: 0.68\n",
            "Validation Loss: 0.70\n",
            "\n",
            " Epoch 14 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.72\n",
            "\n",
            " Epoch 15 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 16 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.67\n",
            "\n",
            " Epoch 17 / 20\n",
            "Train Loss: 0.68\n",
            "Validation Loss: 0.67\n",
            "\n",
            " Epoch 18 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.71\n",
            "\n",
            " Epoch 19 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.71\n",
            "\n",
            " Epoch 20 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.68\n"
          ]
        }
      ],
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    train_loss, _ = train(model, train_dataloader, criterion, optimizer)\n",
        "    valid_loss, _ = evaluate(model, val_dataloader, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         9\n",
            "           1       0.59      1.00      0.74        13\n",
            "\n",
            "    accuracy                           0.59        22\n",
            "   macro avg       0.30      0.50      0.37        22\n",
            "weighted avg       0.35      0.59      0.44        22\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. Model Evaluation\n",
        "Including comparison of models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhkmytKNU_Z2"
      },
      "source": [
        "<a name=\"results-and-discussion\"></a>\n",
        "# Results & Discussion\n",
        "\n",
        "In this section, describe and contextualize the results shown in the tutorial. Briefly describe the performance metrics and cross validation techniques used. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LWo6UQzwj37"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHIjM6eMwlXY"
      },
      "source": [
        "Finally, include a discussion on the limitations and important takeaways from the exercise.\n",
        "\n",
        "## Limitations\n",
        "*   The tutorial is focused on education and learning. Explain all the simplifications you have made compared to applying a similar approach in the real world (for instance, if you have reduced your training data and performance).\n",
        "*   ML algorithms and datasets can reinforce or reflect unfair biases. Reflect on the potential biases in the dataset and/or analysis presented in your tutorial, including its potential societal impact, and discuss how readers might go about addressing this challenge. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLLCQpv14Gsx"
      },
      "source": [
        "## Next Steps\n",
        "*   What do you recommend would be the next steps for your readers after finishing your tutorial?\n",
        "*   Discuss other potential policy- and government-related applications for the method or tool discussed in the tutorial.\n",
        "*   List anything else that you would want the reader to take away as they move on from the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkKqewK_-ZLD"
      },
      "source": [
        "<a name=\"references\"></a>\n",
        "# References\n",
        "\n",
        "Include all references used. \n",
        "\n",
        "For example, in this template:\n",
        "\n",
        "*   EarthCube Notebook Template: https://github.com/earthcube/NotebookTemplates\n",
        "*   Earth Engine Community Tutorials Style Guide: https://developers.google.com/earth-engine/tutorials/community/styleguide#colab\n",
        "*   Google Cloud Community Tutorial Style Guide: https://cloud.google.com/community/tutorials/styleguide\n",
        "*   Rule A, Birmingham A, Zuniga C, Altintas I, Huang S-C, Knight R, et al. (2019) Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks. PLoS Comput Biol 15(7): e1007007. https://doi.org/10.1371/journal.pcbi.1007007\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YguJayU8RBmd"
      },
      "source": [
        "## Acknowledgement\n",
        "\n",
        "These guidelines are heavily based on the Climate Change AI template for the for the tutorials track at the [NeurIPS 2021 Workshop on Tackling Climate Change with Machine Learning](https://www.climatechange.ai/events/neurips2021). "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('watermelon')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "d937f221309e89928364c8f95c616932ec42e1a35308f59658ba617ce90f29fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
