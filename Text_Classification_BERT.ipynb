{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13i7KQ9t-CV8"
      },
      "source": [
        "# Classification of Unstructured Documents \n",
        "## *Transfer Learning with BERT*\n",
        "### GRAD-E1394 Deep Learning\n",
        "\n",
        "---\n",
        "\n",
        "Authors:\n",
        "*   Ma. Adelle Gia Arbo, m.arbo@students.hertie-school.org\n",
        "*   Janine De Vera, j.devera@students.hertie-school.org\n",
        "*   Lorenzo Gini, l.gini@students.hertie-school.org\n",
        "*   Lukas Warode, l.warode@students.hertie-school.org | lukas.warode@gmx.de\n",
        "\n",
        "---\n",
        "\n",
        "This tutorial demonstrates the pipeline for classifying unstructured documents, particularly those in PDF format. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNv0ANr5WcD_"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "\n",
        "*   [Memo](#memo)\n",
        "*   [Overview](#overview)\n",
        "*   [Background & Prerequisites](#background-and-prereqs)\n",
        "*   [Software Requirements](#software-requirements)\n",
        "*   [Data Description](#data-description)\n",
        "*   [Methodology](#methodology)\n",
        "*   [Results & Discussion](#results-and-discussion)\n",
        "*   [References](#references)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH81wjfsJsv1"
      },
      "source": [
        "<a name=\"memo\"></a>\n",
        "# Memo\n",
        "\n",
        "Write a memo for the leadership explaining in layman's terms why this topic is relevant for public policy. Discuss relevant research works, real-world examples of successful applications, and organizations and governments that apply such approaches for policy making. \n",
        "\n",
        "\n",
        "### *Sketch Lukas (not done)*\n",
        "\n",
        "#### Main Point / Take Away (Executive Summary???)\n",
        "\n",
        "#### Background \n",
        "\n",
        "Companies as well as public and political institutions are able and ofent required to access loads of information nowadays. In doing that, they often face the problem of unstructured information, especially when dealing with text data. Data in textual form is the most common type of unstructured, unfortunately, it is also representing the most fundamental type of documents with respect to policymakers and public institutions: Legal documents, bills and policy papers are just some examples of common text sources, which are part of the daily business in the political world. Unstructured text data entails a variety of different problems when it comes actually gaining quantitative analytical insights from them. Computers commonly have difficulties understanding textual data. Analytical and technical competences are also scarce: Only 18% of companies are able to use unstructured data, while most organizations are make their (data-driven) decisions on the basis of only 10 to 20% of their available data source. The situation for public institutions is worsend by the fact that most of the modern text data analysis frameworks and models are dominated by different industry players, while being designed and trained according to the industry-specific needs, which do not transfer to the needs of the mentioned political text sources. The EU Commission (or directly mention DMA?) …\n",
        "\n",
        "This motivates the necessity of implementing …\n",
        "\n",
        "#### Evidence (Sktech our technical solution?)\n",
        "- Text Classification Pipepline + BERT Model(ling)\n",
        "\n",
        "- Results??\n",
        "\n",
        "\n",
        "#### Conclusion and Implementation\n",
        "\n",
        "- Results??\n",
        "\n",
        "- Being specific about implementation and actual usage (maybe even specify DMA context a bit more and say who and what stakeholders/institutions are taking what position in context)\n",
        "\n",
        "*Open points*\n",
        "\n",
        "- Include practicality and gained efficiency\n",
        "- Normative perspective: \"Technical\" objectivity (but one needs to be careful for potential biases)\n",
        "\n",
        "\\\n",
        "- Directly mention DMA at beginning?\n",
        "- How structured should the memo be?\n",
        "\n",
        "\\\n",
        "- Sources need to be added for numbers of slides (e.g. 18% of companies blabla)\n",
        "\n",
        "\n",
        "*Structure*\n",
        "![](https://mitcommlab.mit.edu/broad/wp-content/uploads/sites/5/2017/12/policy-memo-struct-700x843.png)\n",
        "\n",
        "![](https://www.bu.edu/sph/files/2014/06/Policy-Memo-Organization.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2u40fYe3EOL"
      },
      "source": [
        "<a name=\"overview\"></a>\n",
        "# Overview\n",
        "\n",
        "Over 80% of all data is *unstructured*. Most of the information we consume come in a format that is not organized in a pre-defined manner (e.g. tables) or with a specific data model in mind (e.g. matrices). \n",
        "\n",
        "<u>Text</u> is the most common type of unstructured data and it comes in a variety of forms like blogs, news articles, social media content, as well as official documents. This lack of structure that can be readily understood by machines is what makes it difficult to maximize text as a data source. Algorithms that efficiently and accurately process text would have a variety of applications in organisations, especially public institutions that have access to different types of documents. \n",
        "\n",
        "In this tutorial we demonstrate one such application in the context of the European Commission (EC). Whenever new legislation is proposed, the EC opens **public consultations** where various stakeholders (e.g. businesses, academia, law firms, associations, private individuals) submit documents that detail their views on the proposal. The EC receives anywhere between 10,000 to 4 million of these public consultation documents annually. Using machine learning and deep learning methods to process these documents would streamline the Commission's review of stakeholder comments, which will consequently allow them to integrate more information into their policymaking process. \n",
        "\n",
        "The main goal of this tutorial is to walk you through the steps of building a <u>document classifier</u> using a deep learning model called **Bidirectional Encoder Representations from Transformers (BERT)**. By the end of this tutorial you will understand how to:  \n",
        "\n",
        "> 1. Extract, clean, and pre-process information from PDF documents\n",
        "> 2. Use the pre-processed text as input to machine learning/deep learning models\n",
        "> 3. Build a text/document classifier with BERT \n",
        "> 4. Compare BERT with text classifiers built using other models\n",
        "\n",
        "We will then apply these learnings to accomplish a research objective: \n",
        "\n",
        " > Classify public consultation documents of the recently enacted **Digital Markets Act** according to whether a stakeholder **agrees or disagrees** with the DMA proposal. \n",
        "\n",
        "The Digital Markets Act is a regulation in the European Union which came into force this 2022. It aims to promote fair competition within the digital market by defining rules for “gatekeepers” or large online platforms. Majority of the public consultation documents submitted for the DMA are from companies and business associations who will likely be affected by the law."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQgijl46pYzn"
      },
      "source": [
        "<a name=\"background-and-prereqs\"></a>\n",
        "# Background & Prerequisites\n",
        "\n",
        "For this tutorial, you would need to be familiar with object oriented programming, common python libraries such as *numpy* and *pandas*, and libraries used for model building, such as *scikit-learn* and *pytorch*. Working knowledge of common language processing concepts (e.g. stemming, lemmatization, TF-IDF, embeddings) would also be useful. \n",
        "\n",
        "Important concepts that need to be explained briefly:  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7BpQklEEIFDD"
      },
      "source": [
        "## Reading materials\n",
        "\n",
        "For detailed explanations of the topics covered in this tutorial, below is a list helpful references.\n",
        "\n",
        "**Basics of natural language processing models:**\n",
        "* Vajjala, S., Majumder, B., Gupta, A., & Surana, H. (2020). Practical natural language processing: a comprehensive guide to building real-world NLP systems. O'Reilly Media.\n",
        "\n",
        "\n",
        "**BERT:**\n",
        "* Horev, R. (2018). BERT Explained: State of the art language model for NLP. Towards Data Science, 10.\n",
        "* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSRCNgYzUwaf"
      },
      "source": [
        "<a name=\"software-requirements\"></a>\n",
        "# Software Requirements\n",
        "To install software requirements and dependencies, please create a new environment using the *environment.yml* file which accompanies this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!conda env create -f environment.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "xVzk4V7qUu2R"
      },
      "outputs": [],
      "source": [
        "# Data visualization\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parsing and pre-processing\n",
        "from glob import glob\n",
        "import os \n",
        "import re\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "from langdetect import detect, DetectorFactory\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from string import punctuation\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector representations and embeddings\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Logistic and XGboost\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_score, recall_score\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/janinedevera/opt/miniconda3/envs/watermelon/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# LSTM \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BERT models\n",
        "from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# specify GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXoiLncsU3pe"
      },
      "source": [
        "<a name=\"data-description\"></a>\n",
        "# Data Description\n",
        "\n",
        "As mentioned in the [Overview](#overview), the methods discussed in this tutorial will be applied to public consultation documents of the **Digital Markets Act (DMA)**. Respondents answered a survey where they were asked a series of questions about the proposed law. The public consultation received **188 survey responses**. Some respondents also provided **accompanying position papers and reports** where they discuss their views in detail. \n",
        "\n",
        "To build our document classifier we need the raw **text** from the public consultation submissions, and a corresponding **label** for each document which indicates whether or not the author/s agree or disagree with the DMA proposal. \n",
        "\n",
        "**Text:**\n",
        "The submissions come in the form of **pdf files**. These documents need to be parsed in order to extract raw text. \n",
        "\n",
        "**Labels:**\n",
        "The labels are extracted from the **survey**, specifically from the question: \n",
        "\n",
        "> *\"Do you consider that there is a need for the Commission to be able to intervene in gatekeeper scenarios to prevent/address structural competition problems?\"*\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoF-BxSM5Jkc"
      },
      "source": [
        "## Data Download\n",
        "\n",
        "The pdf documents and the survey used to generate labels can be downloaded from the <a href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12416-New-competition-tool/public-consultation_en\">DMA consultation page</a>. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSt6h_Q-oqjK"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A. Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, create a list of file paths of all pdf submissions: `pdf_list`. \n",
        "\n",
        "Each of the downloaded public consultation documents have a unique alpha-numeric ID. For example: the document ID for **\"F549293-Statement_on_the_New_Competition_Tool\"** is *F549293*. A regular expression is used to extract this from the file paths. The IDs are then saved in a list called `pdf_id`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_dir = \"data/reports/\"\n",
        "pdf_list = glob(os.path.join(pdf_dir, \"*.pdf\"))\n",
        "len(pdf_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_id = [re.search('[F][0-9]{6}', i)[0] for i in pdf_list]\n",
        "pdf_id = list(set(pdf_id))\n",
        "len(pdf_id) # no. of unique pdf submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Excel file containing survey answers and details about the respondents is imported as a pandas dataframe. The survey dataset also has a reference column which corresponds to the reference numbers in `pdf_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reference</th>\n",
              "      <th>Feedback date</th>\n",
              "      <th>Language</th>\n",
              "      <th>User type</th>\n",
              "      <th>First name</th>\n",
              "      <th>Surname</th>\n",
              "      <th>Scope</th>\n",
              "      <th>Organisation name</th>\n",
              "      <th>Transparency register number</th>\n",
              "      <th>Organisation size</th>\n",
              "      <th>...</th>\n",
              "      <th>Q197</th>\n",
              "      <th>Q198</th>\n",
              "      <th>Q199</th>\n",
              "      <th>Q200</th>\n",
              "      <th>Q201</th>\n",
              "      <th>Q202</th>\n",
              "      <th>Q203</th>\n",
              "      <th>Q204</th>\n",
              "      <th>Q205</th>\n",
              "      <th>Q206</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F550828</td>\n",
              "      <td>8.09.2020 23:57</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>See our response above.</td>\n",
              "      <td>Somewhat effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>Most effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>See our response above.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No.</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F550827</td>\n",
              "      <td>8.09.2020 23:54</td>\n",
              "      <td>English</td>\n",
              "      <td>NGO (Non-governmental organisation)</td>\n",
              "      <td>Juliane</td>\n",
              "      <td>von Reppert-Bismarck</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lie Detectors</td>\n",
              "      <td>094738529674-10</td>\n",
              "      <td>Small (&lt; 50 employees)</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not effective</td>\n",
              "      <td>Most effective</td>\n",
              "      <td>Somewhat effective</td>\n",
              "      <td>Most effective</td>\n",
              "      <td>Most effective</td>\n",
              "      <td>An additional regulatory framework imposing ob...</td>\n",
              "      <td>Lie_Detectors_-_Digital_Services_Act_-_New_Com...</td>\n",
              "      <td>Please see attached submission</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F550826</td>\n",
              "      <td>8.09.2020 23:50</td>\n",
              "      <td>German</td>\n",
              "      <td>Business Association</td>\n",
              "      <td>Antje</td>\n",
              "      <td>Woltermann</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Zentralverband Deutsches Kfz-Gewerbe e.V.</td>\n",
              "      <td>71649103246-10</td>\n",
              "      <td>Medium (&lt; 250 employees)</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Somewhat effective</td>\n",
              "      <td>Most effective</td>\n",
              "      <td>Somewhat effective</td>\n",
              "      <td>Sufficiently effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>-</td>\n",
              "      <td>Positionspapier_Gleichberechtigter_Zugang_zum_...</td>\n",
              "      <td>-</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F550825</td>\n",
              "      <td>8.09.2020 23:45</td>\n",
              "      <td>English</td>\n",
              "      <td>Academic/Research Institution</td>\n",
              "      <td>DIANA</td>\n",
              "      <td>MONTENEGRO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Master student candidate Master in Competition...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Large (250 or more)</td>\n",
              "      <td>...</td>\n",
              "      <td>The new procedural must be agile.</td>\n",
              "      <td>Not effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>all are adequated</td>\n",
              "      <td>PREPARATIVE_DOCUMENT_FOR_THE_EUROEPAN_COMMISIO...</td>\n",
              "      <td>The document I prepared was more than 1MB.</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F550824</td>\n",
              "      <td>8.09.2020 23:33</td>\n",
              "      <td>English</td>\n",
              "      <td>Business Association</td>\n",
              "      <td>Kamila</td>\n",
              "      <td>Sotomska</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Zwi?zek Przedsi?biorców i Pracodawców</td>\n",
              "      <td>868073924175-77</td>\n",
              "      <td>Small (&lt; 50 employees)</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not applicable /No relevant experience or know...</td>\n",
              "      <td>Not applicable /No relevant experience or know...</td>\n",
              "      <td>Not applicable /No relevant experience or know...</td>\n",
              "      <td>Not applicable /No relevant experience or know...</td>\n",
              "      <td>Not applicable /No relevant experience or know...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 219 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Reference    Feedback date Language                            User type  \\\n",
              "0   F550828  8.09.2020 23:57  English                                  NaN   \n",
              "1   F550827  8.09.2020 23:54  English  NGO (Non-governmental organisation)   \n",
              "2   F550826  8.09.2020 23:50   German                 Business Association   \n",
              "3   F550825  8.09.2020 23:45  English        Academic/Research Institution   \n",
              "4   F550824  8.09.2020 23:33  English                 Business Association   \n",
              "\n",
              "  First name               Surname Scope  \\\n",
              "0        NaN                   NaN   NaN   \n",
              "1    Juliane  von Reppert-Bismarck   NaN   \n",
              "2      Antje            Woltermann   NaN   \n",
              "3      DIANA            MONTENEGRO   NaN   \n",
              "4     Kamila              Sotomska   NaN   \n",
              "\n",
              "                                   Organisation name  \\\n",
              "0                                                NaN   \n",
              "1                                      Lie Detectors   \n",
              "2          Zentralverband Deutsches Kfz-Gewerbe e.V.   \n",
              "3  Master student candidate Master in Competition...   \n",
              "4              Zwi?zek Przedsi?biorców i Pracodawców   \n",
              "\n",
              "  Transparency register number         Organisation size  ...  \\\n",
              "0                          NaN                       NaN  ...   \n",
              "1              094738529674-10    Small (< 50 employees)  ...   \n",
              "2               71649103246-10  Medium (< 250 employees)  ...   \n",
              "3                          NaN       Large (250 or more)  ...   \n",
              "4              868073924175-77    Small (< 50 employees)  ...   \n",
              "\n",
              "                                Q197  \\\n",
              "0            See our response above.   \n",
              "1                                NaN   \n",
              "2                                NaN   \n",
              "3  The new procedural must be agile.   \n",
              "4                                NaN   \n",
              "\n",
              "                                                Q198  \\\n",
              "0                                 Somewhat effective   \n",
              "1                                      Not effective   \n",
              "2                                 Somewhat effective   \n",
              "3                                      Not effective   \n",
              "4  Not applicable /No relevant experience or know...   \n",
              "\n",
              "                                                Q199  \\\n",
              "0                                     Very effective   \n",
              "1                                     Most effective   \n",
              "2                                     Most effective   \n",
              "3                                     Very effective   \n",
              "4  Not applicable /No relevant experience or know...   \n",
              "\n",
              "                                                Q200  \\\n",
              "0                                     Very effective   \n",
              "1                                 Somewhat effective   \n",
              "2                                 Somewhat effective   \n",
              "3                                     Very effective   \n",
              "4  Not applicable /No relevant experience or know...   \n",
              "\n",
              "                                                Q201  \\\n",
              "0                                     Most effective   \n",
              "1                                     Most effective   \n",
              "2                             Sufficiently effective   \n",
              "3                                     Very effective   \n",
              "4  Not applicable /No relevant experience or know...   \n",
              "\n",
              "                                                Q202  \\\n",
              "0                                     Very effective   \n",
              "1                                     Most effective   \n",
              "2                                     Very effective   \n",
              "3                                     Very effective   \n",
              "4  Not applicable /No relevant experience or know...   \n",
              "\n",
              "                                                Q203  \\\n",
              "0                            See our response above.   \n",
              "1  An additional regulatory framework imposing ob...   \n",
              "2                                                  -   \n",
              "3                                  all are adequated   \n",
              "4                                                NaN   \n",
              "\n",
              "                                                Q204  \\\n",
              "0                                                NaN   \n",
              "1  Lie_Detectors_-_Digital_Services_Act_-_New_Com...   \n",
              "2  Positionspapier_Gleichberechtigter_Zugang_zum_...   \n",
              "3  PREPARATIVE_DOCUMENT_FOR_THE_EUROEPAN_COMMISIO...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                         Q205 Q206  \n",
              "0                                         No.  Yes  \n",
              "1              Please see attached submission  Yes  \n",
              "2                                           -  Yes  \n",
              "3  The document I prepared was more than 1MB.  Yes  \n",
              "4                                         NaN  Yes  \n",
              "\n",
              "[5 rows x 219 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dma = pd.read_excel(\"data/DMA Contributions_Clean.xlsx\", sheet_name='Results')\n",
        "dma.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we saw above, there are only 89 unique PDF submissions. We now check how many of survey respondents submitted supplementary papers and/or reports. An indicator variable is added to the survey dataframe to specify whether a response has an equivalent PDF submission. Note that we can only use observations that have both the document submission and survey response. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "85"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count unique Reference ids with pdf submission/s\n",
        "len(dma.query('Reference in @pdf_id'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    95\n",
              "1    85\n",
              "Name: submit, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tag identifier with pdf submission = 1\n",
        "dma['submit'] = [1 if v in pdf_id else 0 for v in dma['Reference'].values]\n",
        "dma['submit'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The question that will be used as a label is Q132. \n",
        "*\"Do you consider that there is a need for the Commission to be able to intervene in gatekeeper scenarios to prevent/address structural competition problems?\"*\n",
        "\n",
        "We check how many Yes and No responses there are. Respondents who answered not applicable can be considered as **not in agreement** with the proposal. Their answers are lumped together with the No responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Yes                                                    115\n",
              "Not applicable /no relevant experience or knowledge     46\n",
              "No                                                      19\n",
              "Name: Q132, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Q132 as labels\n",
        "dma.Q132.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Yes    115\n",
              "No      65\n",
              "Name: label_132, dtype: int64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dma['label_132'] = np.where(dma['Q132'] == 'Not applicable /no relevant experience or knowledge', 'No', dma['Q132'])\n",
        "dma.label_132.value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9Iuu2GU52Z"
      },
      "source": [
        "<a name=\"methodology\"></a>\n",
        "# Methodology\n",
        "\n",
        "This section of the tutorial is a step-by-step walkthrough of text classification pipeline, using DMA public consultation documents as described above. Below is an outline of this section: \n",
        "\n",
        "<ol type=\"A\">\n",
        "  <li>Data Preparation </li>\n",
        "  <li>Text Representation</li>\n",
        "  <li>Model Training (with hyperparameter tuning)</li>\n",
        "  <ol>\n",
        "    <li> Training baseline models (logistic, XGBoost)\n",
        "    <li> Training a DL classifier (LSTM)\n",
        "    <li> Transfer learning with BERT and other variants\n",
        "  </ol>\n",
        "  <li> Model Evaluation\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWXsiZ5freTG"
      },
      "source": [
        "## A. Data Preparation \n",
        "In this section of the tutorial, we will (1) parse PDF submissions from the Digital Markets Act public consultation and (2) pre-process raw text to keep only the most relevant information. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A.1 Parsing PDFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PDF (Portable Document Format) documents are hard to work with because this format was not designed as a data input. Instead, the PDF contains a set of instructions that describe how characters or objects are positioned on a page. \n",
        "\n",
        "Python has text analytics libraries that convert PDFs into the required encoding format. There are several of these PDF libraries, however, they sometimes yield varying results. Here, we demonstrate one such library, `pdfminer`. We have also tried other libraries like `pdfplumber`, so feel free to also experiment on which PDF parser works best for your corpus. \n",
        "\n",
        "We create a dataframe `df_text` which contains information for each document - the reference number (unique ID), file name, and complete text of the document. The full text of the document is parsed using the PDF library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reference</th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F550241</td>\n",
              "      <td>F550241-190326-Dobson_report-FINAL_VERSION.</td>\n",
              "      <td>Ref. Ares(2020)4669723 - 08/09/2020\\n\\nLEVELLI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F550737</td>\n",
              "      <td>F550737-Mediaset_-_NCT_-_Position_paper_-_fina...</td>\n",
              "      <td>New Competition Tool \\n\\nPosition Paper \\n\\nMe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F550604</td>\n",
              "      <td>F550604-LUISS_Study-Executive-summary.</td>\n",
              "      <td>Ref. Ares(2020)4713545 - 09/09/2020\\n\\nTHE EUR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F541861</td>\n",
              "      <td>F541861-ACT_-_Perspectives_on_the_NCT_-_FINAL.</td>\n",
              "      <td>ACT PERSPECTIVES ON THE NEW COMPETITION TOOL \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F549332</td>\n",
              "      <td>F549332-MCA_DSA_and_NCT_public_consultation_po...</td>\n",
              "      <td>The  Malta  Communications  Authority’s  ratio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Reference                                          file_name  \\\n",
              "0   F550241        F550241-190326-Dobson_report-FINAL_VERSION.   \n",
              "1   F550737  F550737-Mediaset_-_NCT_-_Position_paper_-_fina...   \n",
              "2   F550604             F550604-LUISS_Study-Executive-summary.   \n",
              "3   F541861     F541861-ACT_-_Perspectives_on_the_NCT_-_FINAL.   \n",
              "4   F549332  F549332-MCA_DSA_and_NCT_public_consultation_po...   \n",
              "\n",
              "                                                text  \n",
              "0  Ref. Ares(2020)4669723 - 08/09/2020\\n\\nLEVELLI...  \n",
              "1  New Competition Tool \\n\\nPosition Paper \\n\\nMe...  \n",
              "2  Ref. Ares(2020)4713545 - 09/09/2020\\n\\nTHE EUR...  \n",
              "3  ACT PERSPECTIVES ON THE NEW COMPETITION TOOL \\...  \n",
              "4  The  Malta  Communications  Authority’s  ratio...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_text = pd.DataFrame(columns = ['Reference', 'file_name', 'text'])\n",
        "\n",
        "for pdf_file in pdf_list:\n",
        "    Reference = re.search('[F][0-9]{6}', pdf_file)[0]\n",
        "    file_name = re.search('[F][0-9]{6}(.*)[\\\\>.]', pdf_file)[0]\n",
        "    text = extract_text(pdf_file)\n",
        "    row = pd.DataFrame({'Reference': Reference,'file_name': file_name, 'text': text}, index=[0])\n",
        "    df_text = pd.concat([row,df_text.loc[:]]).reset_index(drop=True)\n",
        "\n",
        "df_text.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`df_text` is merged with the `dma` dataframe created in the [Data Description](#data-description) section using the unique Reference code of each document and respondent. Out of the 188 survey responses, only 85 have pdf submissions and some are duplicated. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reference</th>\n",
              "      <th>Feedback date</th>\n",
              "      <th>Language</th>\n",
              "      <th>User type</th>\n",
              "      <th>First name</th>\n",
              "      <th>Surname</th>\n",
              "      <th>Scope</th>\n",
              "      <th>Organisation name</th>\n",
              "      <th>Transparency register number</th>\n",
              "      <th>Organisation size</th>\n",
              "      <th>...</th>\n",
              "      <th>Q201</th>\n",
              "      <th>Q202</th>\n",
              "      <th>Q203</th>\n",
              "      <th>Q204</th>\n",
              "      <th>Q205</th>\n",
              "      <th>Q206</th>\n",
              "      <th>submit</th>\n",
              "      <th>label_132</th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F550828</td>\n",
              "      <td>8.09.2020 23:57</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Most effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>See our response above.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F550827</td>\n",
              "      <td>8.09.2020 23:54</td>\n",
              "      <td>English</td>\n",
              "      <td>NGO (Non-governmental organisation)</td>\n",
              "      <td>Juliane</td>\n",
              "      <td>von Reppert-Bismarck</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lie Detectors</td>\n",
              "      <td>094738529674-10</td>\n",
              "      <td>Small (&lt; 50 employees)</td>\n",
              "      <td>...</td>\n",
              "      <td>Most effective</td>\n",
              "      <td>Most effective</td>\n",
              "      <td>An additional regulatory framework imposing ob...</td>\n",
              "      <td>Lie_Detectors_-_Digital_Services_Act_-_New_Com...</td>\n",
              "      <td>Please see attached submission</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>F550827-Lie_Detectors_-_Digital_Services_Act_-...</td>\n",
              "      <td>8 Sept, 2020 \\n\\nDigital Services Act and New ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F550826</td>\n",
              "      <td>8.09.2020 23:50</td>\n",
              "      <td>German</td>\n",
              "      <td>Business Association</td>\n",
              "      <td>Antje</td>\n",
              "      <td>Woltermann</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Zentralverband Deutsches Kfz-Gewerbe e.V.</td>\n",
              "      <td>71649103246-10</td>\n",
              "      <td>Medium (&lt; 250 employees)</td>\n",
              "      <td>...</td>\n",
              "      <td>Sufficiently effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>-</td>\n",
              "      <td>Positionspapier_Gleichberechtigter_Zugang_zum_...</td>\n",
              "      <td>-</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>F550826-Positionspapier_Gleichberechtigter_Zug...</td>\n",
              "      <td>Ref. Ares(2020)4723306 - 10/09/2020\\n\\nGemeins...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F550825</td>\n",
              "      <td>8.09.2020 23:45</td>\n",
              "      <td>English</td>\n",
              "      <td>Academic/Research Institution</td>\n",
              "      <td>DIANA</td>\n",
              "      <td>MONTENEGRO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Master student candidate Master in Competition...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Large (250 or more)</td>\n",
              "      <td>...</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>Very effective</td>\n",
              "      <td>all are adequated</td>\n",
              "      <td>PREPARATIVE_DOCUMENT_FOR_THE_EUROEPAN_COMMISIO...</td>\n",
              "      <td>The document I prepared was more than 1MB.</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>F550825-PREPARATIVE_DOCUMENT_FOR_THE_EUROEPAN_...</td>\n",
              "      <td>Ref. Ares(2020)4723305 - 10/09/2020\\n\\nTHE LEG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F550824</td>\n",
              "      <td>8.09.2020 23:33</td>\n",
              "      <td>English</td>\n",
              "      <td>Business Association</td>\n",
              "      <td>Kamila</td>\n",
              "      <td>Sotomska</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Zwi?zek Przedsi?biorców i Pracodawców</td>\n",
              "      <td>868073924175-77</td>\n",
              "      <td>Small (&lt; 50 employees)</td>\n",
              "      <td>...</td>\n",
              "      <td>Not applicable /No relevant experience or know...</td>\n",
              "      <td>Not applicable /No relevant experience or know...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 223 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Reference    Feedback date Language                            User type  \\\n",
              "0   F550828  8.09.2020 23:57  English                                  NaN   \n",
              "1   F550827  8.09.2020 23:54  English  NGO (Non-governmental organisation)   \n",
              "2   F550826  8.09.2020 23:50   German                 Business Association   \n",
              "3   F550825  8.09.2020 23:45  English        Academic/Research Institution   \n",
              "4   F550824  8.09.2020 23:33  English                 Business Association   \n",
              "\n",
              "  First name               Surname Scope  \\\n",
              "0        NaN                   NaN   NaN   \n",
              "1    Juliane  von Reppert-Bismarck   NaN   \n",
              "2      Antje            Woltermann   NaN   \n",
              "3      DIANA            MONTENEGRO   NaN   \n",
              "4     Kamila              Sotomska   NaN   \n",
              "\n",
              "                                   Organisation name  \\\n",
              "0                                                NaN   \n",
              "1                                      Lie Detectors   \n",
              "2          Zentralverband Deutsches Kfz-Gewerbe e.V.   \n",
              "3  Master student candidate Master in Competition...   \n",
              "4              Zwi?zek Przedsi?biorców i Pracodawców   \n",
              "\n",
              "  Transparency register number         Organisation size  ...  \\\n",
              "0                          NaN                       NaN  ...   \n",
              "1              094738529674-10    Small (< 50 employees)  ...   \n",
              "2               71649103246-10  Medium (< 250 employees)  ...   \n",
              "3                          NaN       Large (250 or more)  ...   \n",
              "4              868073924175-77    Small (< 50 employees)  ...   \n",
              "\n",
              "                                                Q201  \\\n",
              "0                                     Most effective   \n",
              "1                                     Most effective   \n",
              "2                             Sufficiently effective   \n",
              "3                                     Very effective   \n",
              "4  Not applicable /No relevant experience or know...   \n",
              "\n",
              "                                                Q202  \\\n",
              "0                                     Very effective   \n",
              "1                                     Most effective   \n",
              "2                                     Very effective   \n",
              "3                                     Very effective   \n",
              "4  Not applicable /No relevant experience or know...   \n",
              "\n",
              "                                                Q203  \\\n",
              "0                            See our response above.   \n",
              "1  An additional regulatory framework imposing ob...   \n",
              "2                                                  -   \n",
              "3                                  all are adequated   \n",
              "4                                                NaN   \n",
              "\n",
              "                                                Q204  \\\n",
              "0                                                NaN   \n",
              "1  Lie_Detectors_-_Digital_Services_Act_-_New_Com...   \n",
              "2  Positionspapier_Gleichberechtigter_Zugang_zum_...   \n",
              "3  PREPARATIVE_DOCUMENT_FOR_THE_EUROEPAN_COMMISIO...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                         Q205 Q206 submit label_132  \\\n",
              "0                                         No.  Yes      0       Yes   \n",
              "1              Please see attached submission  Yes      1       Yes   \n",
              "2                                           -  Yes      1       Yes   \n",
              "3  The document I prepared was more than 1MB.  Yes      1       Yes   \n",
              "4                                         NaN  Yes      0       Yes   \n",
              "\n",
              "                                           file_name  \\\n",
              "0                                                NaN   \n",
              "1  F550827-Lie_Detectors_-_Digital_Services_Act_-...   \n",
              "2  F550826-Positionspapier_Gleichberechtigter_Zug...   \n",
              "3  F550825-PREPARATIVE_DOCUMENT_FOR_THE_EUROEPAN_...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                                text  \n",
              "0                                                NaN  \n",
              "1  8 Sept, 2020 \\n\\nDigital Services Act and New ...  \n",
              "2  Ref. Ares(2020)4723306 - 10/09/2020\\n\\nGemeins...  \n",
              "3  Ref. Ares(2020)4723305 - 10/09/2020\\n\\nTHE LEG...  \n",
              "4                                                NaN  \n",
              "\n",
              "[5 rows x 223 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_merged = dma.merge(df_text, how='left', on='Reference')\n",
        "df_merged.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the next step, we only use responses with both PDF submission and label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_merged = df_merged[df_merged['submit']==1]\n",
        "len(df_merged)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A.2 Cleaning and Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After parsing PDFs, we need to further process the raw text to ensure that most of the information we feed into our model/s is relevant to the task at hand. For instance, stopwords like \"the\", \"this\", \"and\" will not give us any indication of whether a stakeholder agrees with a law, so we can remove these words. \n",
        "\n",
        "The pre-processing steps that we apply for this tutorial are the following: \n",
        "\n",
        "1. Removal of stopwords, punctuations, and numeric characters\n",
        "2. Stemming and lemmatization\n",
        "3. Coreference resolution\n",
        "4. Language detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is what the raw text looks like before processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'8 Sept, 2020 \\n\\nDigital Services Act and New Competition Tool  \\n\\nLie Detectors response to public consultations \\n\\nLie  Detectors,  an  award-winning  journalist-led  media  literacy  campaign  in  Europe,  welcomes  the \\nability to respond to the Commission consultation on the Digital Services Act and the New Competition \\nTool.  \\n\\nIn relation to the Digital Services Act consultation, Lie Detectors supports the introduction of Ex Ante \\nRegulation for large online platforms with significant network effects acting as gatekeepers, and of a \\nNew Competition Tool.  \\n\\nThe  instinct  of  regulators  and  policymakers  to  hold  large  platforms  like  Facebook  and  Google  to \\naccount for their role in the proliferation of online disinformation and in the undermining of quality \\njournalism is right. With the necessary political will, solutions exist that will help rein in the epidemic \\nof  disinformation  that  is  sweeping  away  trust  in  established  facts,  in  scientific  method  and  in \\ndemocratic institutions designed to protect us. \\n\\nThe  basis  of  such  solutions  lies  in  taking  on  disinformation  at  its  source,  that  is,  by  taking  on  the \\nbusiness model of large platforms such as Facebook and Google which stoke outrage for revenue and \\nengage  in  the  “monetising  of  lies”  as  the  European  Commission  itself  has  called  it.  Following  the \\nmoney  and  applying  existing  and  new  antitrust  principles  is  a  fundamental  avenue  for  securing \\nEuropean democracy. \\n\\nOther approaches have proven incapable of denting the outrage economy and its corrosive effects on \\ndemocracy.  Fact-checking  initiatives  has  long  been  the  darling  of  conflict-shy  regulators  and \\npolicymakers looking for quick and high-profile fixes. While laudable and valuable to an extent, these \\ninitiatives have proven to touch only the tip of the iceberg. Disinformation has continued to adapt, \\nproliferate and confound the most experienced fact-checkers, evading detection in encrypted spaces \\nand image- and video-based platforms owned by the largest and most powerful platforms. With little \\nrealistic recourse to alternatives, users remain trapped in a cycle of providing data for the platforms’ \\nalgorithms,  which  exacerbate  the  reach  and  effect  of  disinformation.  Foreign  powers  continue  to \\nsubvert democratic processes via manipulative campaigns on the largest platforms. \\n\\nAt the same time, the power of the platforms is has grown exponentially, not only via their dominant \\nposition but also through widely-reported influence-buying campaigns that have gone a significant \\nway to co-opting  the very information sectors they undermine: journalism and media organisations \\nincreasingly  dependent  on  fact-checking  contracts  from  the  platforms;  academia  increasingly \\ndependent  on  data-analysis  contracts  from  the  platforms,  and  even  policymakers  who  see  no \\nalternative but depending on the platforms for rooting out illegal and borderline illegal content one \\npost at a time.   \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0cThe platforms’ non-adherence to the EU Code of Practice on Disinformation, condemned repeatedly \\nby the European Commission, highlights that self-regulation will fail when a business model built on \\ntrapping users and stoking outrage is at stake. \\n\\nThe  ongoing  pandemic  has  thrown  this  into  sharp  relief.  Young  people  report  being  increasingly \\nconcerned about conspiracy theories circulating in their social media groups and have trouble finding \\nreliable information online at a time when that information saves lives. \\n\\nThe European Commission is uniquely placed to withstand the pressures of the platforms and should \\nuse competition tools to investigate links between the advertising business model of the platform and \\nthe dissemination of disinformation.  \\n\\nGatekeeper  designation  and  a  review  of  the  liability  regime  of  digital  services  acting  as  publishers \\nshould  aim  among  other  things  to  re-establishing  some  viability  of  journalism  as  a  fundamental \\ndemocratic  service  to  EU  citizens.  The  challenge  posed  by  large  platforms  requires  new  tools  in \\naddition  to  traditional  competition  law  enforcement  in  order  to  protect  consumers’  interests  and \\ndemocracy itself. \\n\\n-0- \\n\\nLie  Detectors  is  an  award-winning  journalist-led  media-literacy  campaign  in  Europe.  The  non-profit \\norganisation works with more than 200 professional journalists to secure democracy by empowering \\ntens of thousands of young people and their teachers to tackle online disinformation and by fostering \\nunderstanding of quality journalism. Our advocacy arises from the findings of our work with children \\nand teachers across Europe and focuses on tackling disinformation from the demand perspective and \\nthe supply perspective. We have advised the European Commission as a member of the High-Level \\nExpert Group on Fake News and Online Disinformation and the Media Literacy Expert Group.  \\n\\nWhen  addressing  the  demand-side  of  disinformation,  we  support  the  integration  of  critical  media \\nliteracy  into  school  rankings  gauges,  school  curricula  and  teacher-training  curricula,  and  the \\nindependence of journalism and education from corporate interest. \\n\\n \\n \\n \\n \\n \\n \\n \\n \\n\\x0c'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_merged.text[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Removal of stopwords, punctuations, numeric characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_corpus(texts):\n",
        "    eng_stopwords = set(stopwords.words(\"english\"))\n",
        "    def remove_stops_digits(tokens):\n",
        "        token_list =  [token.lower() for token in tokens if token not in eng_stopwords and token not in punctuation and token.isdigit() == False]\n",
        "        processed_text = ' '.join(token_list)\n",
        "        return processed_text\n",
        "    return [remove_stops_digits(word_tokenize(text)) for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_merged['text_clean'] = preprocess_corpus(df_merged['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Stemming and lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stem_lemmatize(text):\n",
        "    stemmed = [stemmer.stem(token) for token in word_tokenize(text)]\n",
        "    lemmatized = [lemmatizer.lemmatize(token) for token in stemmed]\n",
        "    processed_text = ' '.join(lemmatized)\n",
        "    return processed_text\n",
        "\n",
        "df_merged['text_clean'] = [stem_lemmatize(text) for text in df_merged['text_clean']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Coreference resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# installing neuralcoref from source\n",
        "!git clone https://github.com/huggingface/neuralcoref.git\n",
        "!cd neuralcoref\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x16578df70>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "import neuralcoref\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm') \n",
        "neuralcoref.add_to_pipe(nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def coref_res(texts):\n",
        "    doc = nlp(texts)\n",
        "    clean = doc._.coref_resolved\n",
        "    return clean\n",
        "\n",
        "df_merged['text_clean'] = [coref_res(text) for text in df_merged['text_clean']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Language detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Subset dataframe to retain only english text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "en    83\n",
              "de     7\n",
              "fr     2\n",
              "es     1\n",
              "Name: lang, dtype: int64"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for index, row in df_merged.iterrows():\n",
        "    df_merged.at[index, 'lang'] = detect(df_merged.at[index, 'text_clean'])\n",
        "\n",
        "df_merged.lang.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_merged = df_merged[df_merged['lang']==\"en\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Final dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = df_merged[['Reference', 'Feedback date', 'User type', 'Scope', \n",
        "                    'Organisation name', 'Transparency register number', 'Organisation size',\n",
        "                    'label_132', 'submit', 'file_name', 'lang', 'text', 'text_clean']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final.reset_index(drop=True).to_json(r\"../data/df_final_document.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pre-processed text should look like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sept digit servic act new competit tool lie detector respons public consult lie detector award-win journalist-l medium literaci campaign europ welcom abil respond commiss consult digit servic act new competit tool in relat digit servic act consult lie detector support introduct ex ant regul larg onlin platform signific network effect act gatekeep new competit tool the instinct regul policymak hold larg platform like facebook googl account role prolifer onlin disinform undermin qualiti journal right with necessari polit solut exist help rein epidem disinform sweep away trust establish fact scientif method democrat institut design protect u the basi solut lie take disinform sourc take busi model larg platform facebook googl stoke outrag revenu engag “ monetis lie ” european commiss call follow money appli exist new antitrust principl fundament avenu secur european democraci other approach proven incap dent outrag economi corros effect democraci fact-check initi long darl conflict-shi regul policymak look quick high-profil fix while laudabl valuabl extent initi proven touch tip iceberg disinform continu adapt prolifer confound experienc fact-check evad detect encrypt space image- video-bas platform own largest power platform with littl realist recours altern user remain trap cycl provid data platform ’ algorithm exacerb reach effect disinform foreign power continu subvert democrat process via manipul campaign largest platform at time power platform grown exponenti via domin posit also widely-report influence-buy campaign gone signific way co-opt inform sector undermin journal medium organis increasingli depend fact-check contract platform academia increasingli depend data-analysi contract platform even policymak see altern depend platform root illeg borderlin illeg content one post time the platform ’ non-adher eu code practic disinform condemn repeatedli european commiss highlight self-regul fail busi model built trap user stoke outrag stake the ongo pandem thrown sharp relief young peopl report increasingli concern conspiraci theori circul social medium group troubl find reliabl inform onlin time inform save live the european commiss uniqu place withstand pressur platform use competit tool investig link advertis busi model platform dissemin disinform gatekeep design review liabil regim digit servic act publish aim among thing re-establish viabil journal fundament democrat servic eu citizen the challeng pose larg platform requir new tool addit tradit competit law enforc order protect consum ’ interest democraci -0- lie detector award-win journalist-l media-literaci campaign europ the non-profit organis work profession journalist secur democraci empow ten thousand young peopl teacher tackl onlin disinform foster understand qualiti journal our advocaci aris find work child teacher across europ focus tackl disinform demand perspect suppli perspect we advis european commiss member high-level expert group fake news onlin disinform medium literaci expert group when address demand-sid disinform support integr critic medium literaci school rank gaug school curriculum teacher-train curriculum independ journal educ corpor interest'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final.text_clean[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_json(r\"./data/df_final_document.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8L28axZ4NVj"
      },
      "source": [
        "## B. Text Representation\n",
        "In this section of the tutorial, we will demonstrate how to **convert raw text into numerical form** that can be readily fed into different machine learning and deep learning algorithms. There are two main ways to do this - (1) basic vectorization and (2) distributed representations. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B.1 Basic Vectorization\n",
        "Basic vectorization techniques map each word of the corpus vocabulary (V) to a numeric value and represents each document as a V-dimensional vector. These methods are simple and straightforward and can be used to construct ML-based text and document classifiers with interpretable features. The most common methods are one-hot encoding and term frequency–inverse document frequency (TF-IDF). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our TF-IDF matrix has 143 documents with 12,077 features or words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(143, 12077)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "dfm = vectorizer.fit_transform(df['text_clean'])\n",
        "dfm.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B.2 Distibuted Representations\n",
        "Distributed representations or **embeddings** are dense, low-dimensional vectors which capture context and distributional similarities between words. These methods address some fundamental limitations of basic vectorization techniques. First, distributed representations are more computationally efficient since they don't retain the shape of the entire corpus vocabulary. Second, context and similarities between words are accounted for, unlike basic vectorizations where words are treated as atomic units. Finally, they provide a solution to the *out of vocabulary* problem, where a model is unable to represent a word that was not used in the training data. One of the biggest advantage of embeddings is that they are able generalization to unseen text.\n",
        "\n",
        "Word or document embeddings that may be pre-trained based on a big corpus (e.g. Word2Vec or GloVe) or trained based on your own set of documents (using CBOW or SkipGram).\n",
        "Below is an illustration of how to construct TF-IDF weighted word embeddings for our set of DMA consultation documents using pre-trained GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, load the GloVe embeddings which can be download from the NLP Stanford <a href = \"https://nlp.stanford.edu/projects/glove/\">website</a>. We will use the 100-dimensional GloVe embeddings and save it into a matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "dims = 100\n",
        "\n",
        "z = ZipFile(\"data/glove.6B.zip\") # glove zip file saved in data folder\n",
        "f = z.open(f'glove.6B.{dims}d.txt')\n",
        "\n",
        "embed_matrix = pd.read_table(\n",
        "    f, sep = \" \", index_col = 0, \n",
        "    header = None, quoting = csv.QUOTE_NONE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The GloVe embeddings has a 400,000-word vocabulary, with each word represented by a vector of size 100. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embed_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>-0.038194</td>\n",
              "      <td>-0.244870</td>\n",
              "      <td>0.728120</td>\n",
              "      <td>-0.399610</td>\n",
              "      <td>0.083172</td>\n",
              "      <td>0.043953</td>\n",
              "      <td>-0.391410</td>\n",
              "      <td>0.334400</td>\n",
              "      <td>-0.57545</td>\n",
              "      <td>0.087459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016215</td>\n",
              "      <td>-0.017099</td>\n",
              "      <td>-0.389840</td>\n",
              "      <td>0.87424</td>\n",
              "      <td>-0.725690</td>\n",
              "      <td>-0.510580</td>\n",
              "      <td>-0.520280</td>\n",
              "      <td>-0.145900</td>\n",
              "      <td>0.82780</td>\n",
              "      <td>0.270620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>,</th>\n",
              "      <td>-0.107670</td>\n",
              "      <td>0.110530</td>\n",
              "      <td>0.598120</td>\n",
              "      <td>-0.543610</td>\n",
              "      <td>0.673960</td>\n",
              "      <td>0.106630</td>\n",
              "      <td>0.038867</td>\n",
              "      <td>0.354810</td>\n",
              "      <td>0.06351</td>\n",
              "      <td>-0.094189</td>\n",
              "      <td>...</td>\n",
              "      <td>0.349510</td>\n",
              "      <td>-0.722600</td>\n",
              "      <td>0.375490</td>\n",
              "      <td>0.44410</td>\n",
              "      <td>-0.990590</td>\n",
              "      <td>0.612140</td>\n",
              "      <td>-0.351110</td>\n",
              "      <td>-0.831550</td>\n",
              "      <td>0.45293</td>\n",
              "      <td>0.082577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>-0.339790</td>\n",
              "      <td>0.209410</td>\n",
              "      <td>0.463480</td>\n",
              "      <td>-0.647920</td>\n",
              "      <td>-0.383770</td>\n",
              "      <td>0.038034</td>\n",
              "      <td>0.171270</td>\n",
              "      <td>0.159780</td>\n",
              "      <td>0.46619</td>\n",
              "      <td>-0.019169</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.063351</td>\n",
              "      <td>-0.674120</td>\n",
              "      <td>-0.068895</td>\n",
              "      <td>0.53604</td>\n",
              "      <td>-0.877730</td>\n",
              "      <td>0.318020</td>\n",
              "      <td>-0.392420</td>\n",
              "      <td>-0.233940</td>\n",
              "      <td>0.47298</td>\n",
              "      <td>-0.028803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>-0.152900</td>\n",
              "      <td>-0.242790</td>\n",
              "      <td>0.898370</td>\n",
              "      <td>0.169960</td>\n",
              "      <td>0.535160</td>\n",
              "      <td>0.487840</td>\n",
              "      <td>-0.588260</td>\n",
              "      <td>-0.179820</td>\n",
              "      <td>-1.35810</td>\n",
              "      <td>0.425410</td>\n",
              "      <td>...</td>\n",
              "      <td>0.187120</td>\n",
              "      <td>-0.018488</td>\n",
              "      <td>-0.267570</td>\n",
              "      <td>0.72700</td>\n",
              "      <td>-0.593630</td>\n",
              "      <td>-0.348390</td>\n",
              "      <td>-0.560940</td>\n",
              "      <td>-0.591000</td>\n",
              "      <td>1.00390</td>\n",
              "      <td>0.206640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>-0.189700</td>\n",
              "      <td>0.050024</td>\n",
              "      <td>0.190840</td>\n",
              "      <td>-0.049184</td>\n",
              "      <td>-0.089737</td>\n",
              "      <td>0.210060</td>\n",
              "      <td>-0.549520</td>\n",
              "      <td>0.098377</td>\n",
              "      <td>-0.20135</td>\n",
              "      <td>0.342410</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.131340</td>\n",
              "      <td>0.058617</td>\n",
              "      <td>-0.318690</td>\n",
              "      <td>-0.61419</td>\n",
              "      <td>-0.623930</td>\n",
              "      <td>-0.415480</td>\n",
              "      <td>-0.038175</td>\n",
              "      <td>-0.398040</td>\n",
              "      <td>0.47647</td>\n",
              "      <td>-0.159830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chanty</th>\n",
              "      <td>-0.155770</td>\n",
              "      <td>-0.049188</td>\n",
              "      <td>-0.064377</td>\n",
              "      <td>0.223600</td>\n",
              "      <td>-0.201460</td>\n",
              "      <td>-0.038963</td>\n",
              "      <td>0.129710</td>\n",
              "      <td>-0.294510</td>\n",
              "      <td>0.00359</td>\n",
              "      <td>-0.098377</td>\n",
              "      <td>...</td>\n",
              "      <td>0.093324</td>\n",
              "      <td>0.094486</td>\n",
              "      <td>-0.023469</td>\n",
              "      <td>-0.48099</td>\n",
              "      <td>0.623320</td>\n",
              "      <td>0.024318</td>\n",
              "      <td>-0.275870</td>\n",
              "      <td>0.075044</td>\n",
              "      <td>-0.56380</td>\n",
              "      <td>0.145010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kronik</th>\n",
              "      <td>-0.094426</td>\n",
              "      <td>0.147250</td>\n",
              "      <td>-0.157390</td>\n",
              "      <td>0.071966</td>\n",
              "      <td>-0.298450</td>\n",
              "      <td>0.039432</td>\n",
              "      <td>0.021870</td>\n",
              "      <td>0.008041</td>\n",
              "      <td>-0.18682</td>\n",
              "      <td>-0.311010</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.305450</td>\n",
              "      <td>-0.011082</td>\n",
              "      <td>0.118550</td>\n",
              "      <td>-0.11312</td>\n",
              "      <td>0.339510</td>\n",
              "      <td>-0.224490</td>\n",
              "      <td>0.257430</td>\n",
              "      <td>0.631430</td>\n",
              "      <td>-0.20090</td>\n",
              "      <td>-0.105420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rolonda</th>\n",
              "      <td>0.360880</td>\n",
              "      <td>-0.169190</td>\n",
              "      <td>-0.327040</td>\n",
              "      <td>0.098332</td>\n",
              "      <td>-0.429700</td>\n",
              "      <td>-0.188740</td>\n",
              "      <td>0.455560</td>\n",
              "      <td>0.285290</td>\n",
              "      <td>0.30340</td>\n",
              "      <td>-0.366830</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.044082</td>\n",
              "      <td>0.140030</td>\n",
              "      <td>0.300070</td>\n",
              "      <td>-0.12731</td>\n",
              "      <td>-0.143040</td>\n",
              "      <td>-0.069396</td>\n",
              "      <td>0.281600</td>\n",
              "      <td>0.271390</td>\n",
              "      <td>-0.29188</td>\n",
              "      <td>0.161090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zsombor</th>\n",
              "      <td>-0.104610</td>\n",
              "      <td>-0.504700</td>\n",
              "      <td>-0.493310</td>\n",
              "      <td>0.135160</td>\n",
              "      <td>-0.363710</td>\n",
              "      <td>-0.447500</td>\n",
              "      <td>0.184290</td>\n",
              "      <td>-0.056510</td>\n",
              "      <td>0.40474</td>\n",
              "      <td>-0.725830</td>\n",
              "      <td>...</td>\n",
              "      <td>0.151530</td>\n",
              "      <td>-0.108420</td>\n",
              "      <td>0.340640</td>\n",
              "      <td>-0.40916</td>\n",
              "      <td>-0.081263</td>\n",
              "      <td>0.095315</td>\n",
              "      <td>0.150180</td>\n",
              "      <td>0.425270</td>\n",
              "      <td>-0.51250</td>\n",
              "      <td>-0.170540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sandberger</th>\n",
              "      <td>0.283650</td>\n",
              "      <td>-0.626300</td>\n",
              "      <td>-0.443510</td>\n",
              "      <td>0.217700</td>\n",
              "      <td>-0.087421</td>\n",
              "      <td>-0.170620</td>\n",
              "      <td>0.292660</td>\n",
              "      <td>-0.024899</td>\n",
              "      <td>0.26414</td>\n",
              "      <td>-0.170230</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138850</td>\n",
              "      <td>-0.228620</td>\n",
              "      <td>0.071792</td>\n",
              "      <td>-0.43208</td>\n",
              "      <td>0.539800</td>\n",
              "      <td>-0.085806</td>\n",
              "      <td>0.032651</td>\n",
              "      <td>0.436780</td>\n",
              "      <td>-0.82607</td>\n",
              "      <td>-0.157010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400000 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 1         2         3         4         5         6    \\\n",
              "0                                                                        \n",
              "the        -0.038194 -0.244870  0.728120 -0.399610  0.083172  0.043953   \n",
              ",          -0.107670  0.110530  0.598120 -0.543610  0.673960  0.106630   \n",
              ".          -0.339790  0.209410  0.463480 -0.647920 -0.383770  0.038034   \n",
              "of         -0.152900 -0.242790  0.898370  0.169960  0.535160  0.487840   \n",
              "to         -0.189700  0.050024  0.190840 -0.049184 -0.089737  0.210060   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "chanty     -0.155770 -0.049188 -0.064377  0.223600 -0.201460 -0.038963   \n",
              "kronik     -0.094426  0.147250 -0.157390  0.071966 -0.298450  0.039432   \n",
              "rolonda     0.360880 -0.169190 -0.327040  0.098332 -0.429700 -0.188740   \n",
              "zsombor    -0.104610 -0.504700 -0.493310  0.135160 -0.363710 -0.447500   \n",
              "sandberger  0.283650 -0.626300 -0.443510  0.217700 -0.087421 -0.170620   \n",
              "\n",
              "                 7         8        9         10   ...       91        92   \\\n",
              "0                                                  ...                       \n",
              "the        -0.391410  0.334400 -0.57545  0.087459  ...  0.016215 -0.017099   \n",
              ",           0.038867  0.354810  0.06351 -0.094189  ...  0.349510 -0.722600   \n",
              ".           0.171270  0.159780  0.46619 -0.019169  ... -0.063351 -0.674120   \n",
              "of         -0.588260 -0.179820 -1.35810  0.425410  ...  0.187120 -0.018488   \n",
              "to         -0.549520  0.098377 -0.20135  0.342410  ... -0.131340  0.058617   \n",
              "...              ...       ...      ...       ...  ...       ...       ...   \n",
              "chanty      0.129710 -0.294510  0.00359 -0.098377  ...  0.093324  0.094486   \n",
              "kronik      0.021870  0.008041 -0.18682 -0.311010  ... -0.305450 -0.011082   \n",
              "rolonda     0.455560  0.285290  0.30340 -0.366830  ... -0.044082  0.140030   \n",
              "zsombor     0.184290 -0.056510  0.40474 -0.725830  ...  0.151530 -0.108420   \n",
              "sandberger  0.292660 -0.024899  0.26414 -0.170230  ...  0.138850 -0.228620   \n",
              "\n",
              "                 93       94        95        96        97        98   \\\n",
              "0                                                                       \n",
              "the        -0.389840  0.87424 -0.725690 -0.510580 -0.520280 -0.145900   \n",
              ",           0.375490  0.44410 -0.990590  0.612140 -0.351110 -0.831550   \n",
              ".          -0.068895  0.53604 -0.877730  0.318020 -0.392420 -0.233940   \n",
              "of         -0.267570  0.72700 -0.593630 -0.348390 -0.560940 -0.591000   \n",
              "to         -0.318690 -0.61419 -0.623930 -0.415480 -0.038175 -0.398040   \n",
              "...              ...      ...       ...       ...       ...       ...   \n",
              "chanty     -0.023469 -0.48099  0.623320  0.024318 -0.275870  0.075044   \n",
              "kronik      0.118550 -0.11312  0.339510 -0.224490  0.257430  0.631430   \n",
              "rolonda     0.300070 -0.12731 -0.143040 -0.069396  0.281600  0.271390   \n",
              "zsombor     0.340640 -0.40916 -0.081263  0.095315  0.150180  0.425270   \n",
              "sandberger  0.071792 -0.43208  0.539800 -0.085806  0.032651  0.436780   \n",
              "\n",
              "                99        100  \n",
              "0                              \n",
              "the         0.82780  0.270620  \n",
              ",           0.45293  0.082577  \n",
              ".           0.47298 -0.028803  \n",
              "of          1.00390  0.206640  \n",
              "to          0.47647 -0.159830  \n",
              "...             ...       ...  \n",
              "chanty     -0.56380  0.145010  \n",
              "kronik     -0.20090 -0.105420  \n",
              "rolonda    -0.29188  0.161090  \n",
              "zsombor    -0.51250 -0.170540  \n",
              "sandberger -0.82607 -0.157010  \n",
              "\n",
              "[400000 rows x 100 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embed_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find the words in our corpus that are present in the GloVe embedding matrix. Results below show that there are 7,462 in common with the GloVe embedding matrix. We then get the indices of these common words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7462"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "common_features = set(embed_matrix.index) & set(vectorizer.get_feature_names_out())\n",
        "len(common_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_ids = [vectorizer.vocabulary_[x] for x in common_features]\n",
        "vocab_ids[1:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using common feature only, we multiply our 143 x 7462 TF-IDF matrix by the 7462 x 100 embedding matrix to get the document embedding matrix for all consultation documents. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/rd/n9w0gpv53y72x5k9wk3hp63w0000gn/T/ipykernel_32263/3754221714.py:1: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
            "  doc_matrix = dfm[:,vocab_ids].dot(embed_matrix.loc[common_features,])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(143, 100)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_matrix = dfm[:,vocab_ids].dot(embed_matrix.loc[common_features,])\n",
        "doc_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. Model Training (with hyperparameter tuning)\n",
        "In this section of the tutorial, we compare 3 different types text classification models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "df['label.132'] = le.fit_transform(df['label_132'])\n",
        "df['label.134'] = le.fit_transform(df['label_134'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C.1 Baseline Models\n",
        "For our baseline models, we will use traditional ML classifiers - logistic regression and gradient boosting - with the document embedding matrix as features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split data into train, test, validation sets\n",
        "train_text, test_text, train_labels, test_labels = train_test_split(doc_matrix, df['label.132'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label.132'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 67.44 \n",
            " Precision: 0.700 \n",
            " Recall: 0.808 \n",
            " F1: 0.750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/janinedevera/opt/miniconda3/envs/watermelon/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(random_state=0).fit(train_text, train_labels)\n",
        "\n",
        "y_pred = clf.predict(test_text)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, y_pred) *100.0\n",
        "precision = precision_score(test_labels, y_pred, average='binary')\n",
        "recall = recall_score(test_labels, y_pred, average='binary')\n",
        "f_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f' Accuracy: {accuracy:.2f} \\n Precision: {precision:.3f} \\n Recall: {recall:.3f} \\n F1: {f_score:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
            "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
            "              early_stopping_rounds=None, enable_categorical=False,\n",
            "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
            "              grow_policy='depthwise', importance_type=None,\n",
            "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
            "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
            "              max_depth=1000, max_leaves=0, min_child_weight=1, missing=nan,\n",
            "              monotone_constraints='()', n_estimators=1000, n_jobs=0,\n",
            "              num_parallel_tree=1, predictor='auto', random_state=0, ...)\n",
            " Accuracy: 62.79 \n",
            " Precision: 0.667 \n",
            " Recall: 0.769 \n",
            " F1: 0.714\n"
          ]
        }
      ],
      "source": [
        "bst = XGBClassifier(n_estimators=1000, max_depth=1000, learning_rate=0.1, objective='binary:logistic')\n",
        "\n",
        "bst.fit(train_text, train_labels)\n",
        "\n",
        "print(bst)\n",
        "\n",
        "y_pred = bst.predict(test_text)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, y_pred) * 100.0\n",
        "precision = precision_score(test_labels, y_pred, average='binary')\n",
        "recall = recall_score(test_labels, y_pred, average='binary')\n",
        "f_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f' Accuracy: {accuracy:.2f} \\n Precision: {precision:.3f} \\n Recall: {recall:.3f} \\n F1: {f_score:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C.2 Long Short-Term Memory Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After splitting the data into training and test set, build the corpus vocabulary by tokenizing all texts and assigning each word to a unique index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def tokenize(datasets):\n",
        "    for dataset in datasets:\n",
        "        for text in dataset:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(tokenize([train_text, test_text]), min_freq=1, specials=[\"<UNK>\"])\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7332, 1493, 719, 6370, 1]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example\n",
        "tokens = tokenizer(\"This is an example.\")\n",
        "index = vocab(tokens)\n",
        "index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the vocabulary is built, we create batches of text sequences and map the tokens to indices. We also pad the sequence of words so all are of the same length. This returns a tensor of the sequence length and batch size. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_classes = [\"0\", \"1\"]\n",
        "max_words = 100\n",
        "\n",
        "def vectorize_batch(batch):\n",
        "    Y, X = list(zip(*batch))\n",
        "    X = [vocab(tokenizer(text)) for text in X] # map tokes to index using vocab\n",
        "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] # pad sequences\n",
        "\n",
        "    return torch.tensor(X, dtype=torch.int32), torch.tensor(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=100, collate_fn=vectorize_batch, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=100, collate_fn=vectorize_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 100]) torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "for X, Y in train_loader:\n",
        "    print(X.shape, Y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create LSTM classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define hyperparameters\n",
        "embed_len = 100\n",
        "hidden_dim = 60\n",
        "n_layers = 2\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embed_len = embed_len\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len)\n",
        "        self.lstm = nn.LSTM(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, len(target_classes))\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        hidden, carry = torch.randn(n_layers, len(X_batch), hidden_dim), torch.randn(n_layers, len(X_batch), hidden_dim)\n",
        "        output, (hidden, carry) = self.lstm(embeddings, (hidden, carry))\n",
        "        return self.linear(output[:,-1])\n",
        "\n",
        "    def init_hidden(self):\n",
        "      return (\n",
        "               torch.zeros(n_layers, 1, self.hidden_dim, device=device),\n",
        "               torch.zeros(n_layers, 1, self.hidden_dim, device=device)\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTMClassifier(\n",
              "  (embedding_layer): Embedding(14499, 100)\n",
              "  (lstm): LSTM(100, 60, num_layers=2, batch_first=True)\n",
              "  (linear): Linear(in_features=60, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm_classifier = LSTMClassifier()\n",
        "lstm_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer : Embedding(14499, 100)\n",
            "Parameters : \n",
            "torch.Size([14499, 100])\n",
            "\n",
            "Layer : LSTM(100, 60, num_layers=2, batch_first=True)\n",
            "Parameters : \n",
            "torch.Size([240, 100])\n",
            "torch.Size([240, 60])\n",
            "torch.Size([240])\n",
            "torch.Size([240])\n",
            "torch.Size([240, 60])\n",
            "torch.Size([240, 60])\n",
            "torch.Size([240])\n",
            "torch.Size([240])\n",
            "\n",
            "Layer : Linear(in_features=60, out_features=2, bias=True)\n",
            "Parameters : \n",
            "torch.Size([2, 60])\n",
            "torch.Size([2])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for layer in lstm_classifier.children():\n",
        "    print(\"Layer : {}\".format(layer))\n",
        "    print(\"Parameters : \")\n",
        "    for param in layer.parameters():\n",
        "        print(param.shape)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1024, 2])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = lstm_classifier(torch.randint(0, len(vocab), (1024, max_words)))\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, loss_fn, val_loader):\n",
        "    with torch.no_grad():\n",
        "        Y_shuffled, Y_preds, losses = [],[],[]\n",
        "        for X, Y in val_loader:\n",
        "            preds = model(X)\n",
        "            loss = loss_fn(preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            Y_shuffled.append(Y)\n",
        "            Y_preds.append(preds.argmax(dim=-1))\n",
        "\n",
        "        Y_shuffled = torch.cat(Y_shuffled)\n",
        "        Y_preds = torch.cat(Y_preds)\n",
        "\n",
        "        print(\"Valid Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        print(\"Valid Acc  : {:.3f}\".format(accuracy_score(Y_shuffled.detach().numpy(), Y_preds.detach().numpy())))\n",
        "\n",
        "def train(model, loss_fn, optimizer, train_loader, val_loader, epochs=10):\n",
        "    for i in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for X, Y in tqdm(train_loader):\n",
        "            Y_preds = model(X)\n",
        "\n",
        "            loss = loss_fn(Y_preds, Y) \n",
        "            losses.append(loss.item())\n",
        "\n",
        "            ## back propagation\n",
        "            optimizer.zero_grad() \n",
        "            loss.backward() \n",
        "            optimizer.step() \n",
        "\n",
        "        print(\"Train Loss : {:.3f}\".format(torch.tensor(losses).mean()))\n",
        "        evaluate(model, loss_fn, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.697\n",
            "Valid Loss : 0.693\n",
            "Valid Acc  : 0.512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.690\n",
            "Valid Loss : 0.690\n",
            "Valid Acc  : 0.535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.682\n",
            "Valid Loss : 0.686\n",
            "Valid Acc  : 0.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.675\n",
            "Valid Loss : 0.683\n",
            "Valid Acc  : 0.605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.668\n",
            "Valid Loss : 0.679\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.660\n",
            "Valid Loss : 0.676\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.651\n",
            "Valid Loss : 0.673\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.642\n",
            "Valid Loss : 0.669\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.632\n",
            "Valid Loss : 0.666\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.621\n",
            "Valid Loss : 0.662\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.609\n",
            "Valid Loss : 0.659\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.595\n",
            "Valid Loss : 0.656\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.581\n",
            "Valid Loss : 0.653\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.564\n",
            "Valid Loss : 0.651\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.547\n",
            "Valid Loss : 0.651\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.528\n",
            "Valid Loss : 0.652\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.508\n",
            "Valid Loss : 0.655\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.487\n",
            "Valid Loss : 0.660\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.463\n",
            "Valid Loss : 0.665\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss : 0.437\n",
            "Valid Loss : 0.671\n",
            "Valid Acc  : 0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 1e-3\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "lstm_classifier = LSTMClassifier()\n",
        "optimizer = Adam(lstm_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "train(lstm_classifier, loss_fn, optimizer, train_loader, test_loader, epochs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C.3 Transfer Learning with BERT and Other Variants"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Bidirectional Encoder Representations from Transformers** or **BERT** follows the Transformer architecture but it only uses the encoder part. Each transformer encoder consists of two sub-layers: self-attention and feed-forward. The key feature of BERT is its bidirectionality as it learns information from both left and right side of a token’s context. This allows for parallel processing, store the position of the input, and make lookup easy. \n",
        "\n",
        "\n",
        "BERT is trained from BookCorpus (800M words) and English Wikipedia (2.5B words). In a nutshell, BERT reads the input sequence and generates meaningful text representations, which it feeds into the encoder. This can then be augmented with additional neural network layers to fit a classification task. BERT has three embedding layers: token embedding layer, segment embedding layer, and position embedding layer. The element-wise sum of these three layers gives the final input representation.\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"./img/bert_embeddings.png\" width=\"250\" height=\"320\">\n",
        "</p>\n",
        "\n",
        "For NLP related task, the best practice is to use pre-trained models first, and then fine-tune them. This is called **transfer learning**, a technique where a deep learning model trained from a very large dataset is used as “off-the-shelf” to perform similar tasks on another dataset. There are 3 different fine-tuning techniques:\n",
        "> 1. Train the entire architecture which updates all pre-trained weights based on the new dataset\n",
        "> 2. Train the pretrained model partially and freeze the weights of the initial layer and retrain only on the higher levels\n",
        "> 3. Freeze entire architecture and attach a few NN layers to train the new model.\n",
        "\n",
        "In this tutorial, we will implement transfer model using a pre-trained BERT model. After collecting, preparing, and pre-processing the unstructured documents, we split the dataset into training, validation, and testing. We then implement transfer learning using the bert-base-uncased model with 12 encoder transformer layers trained on lower-case English texts. We use the wordpiece embeddings from BERT as inputs to our text classification task.\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"./img/bert_pipeline.png\" width=\"700\" height=\"320\">\n",
        "<p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split data into train, test, validation sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text_clean'], df['label.132'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label.132'])\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# bert-base-uncased\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', return_dict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# legal-bert-base-uncased\n",
        "bert = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", return_dict=False)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", return_dict=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Tokenize the Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert lists to tensors\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "num_workers = 2\n",
        "\n",
        "# dataLoader for train set\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_dataloader = DataLoader(train_data, num_workers=num_workers, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_dataloader = DataLoader(val_data, num_workers=num_workers, shuffle=True, batch_size=batch_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### BERT Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      self.relu =  nn.ReLU()\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      x = self.fc1(cls_hs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# method to freeze all the parameters if freeze = T\n",
        "def set_parameter_requires_grad(model, freeze):\n",
        "    if freeze:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# freeze all parameters\n",
        "set_parameter_requires_grad(model=bert, freeze=True)\n",
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-5) # learning rate\n",
        "\n",
        "# loss function\n",
        "criterion  = nn.NLLLoss() \n",
        "\n",
        "# no. of training epochs\n",
        "epochs = 20"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Fine-tuning BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to train the model\n",
        "def train(model, dataloader, criterion, optimizer):\n",
        "  \n",
        "  model.train()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  running_total_correct = 0.0\n",
        "  total_preds=[]\n",
        "  \n",
        "  for i, inputs in enumerate((dataloader)):\n",
        "    \n",
        "    # push to gpu\n",
        "    inputs = [r.to(device) for r in inputs]\n",
        "    sent_id, mask, labels = inputs\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    model.zero_grad()        \n",
        "\n",
        "    # forward + backward + optimize \n",
        "    preds = model(sent_id, mask)\n",
        "    loss = criterion(preds, labels)\n",
        "    total_loss = total_loss + loss.item()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) #prevent exploding gradient problem\n",
        "    optimizer.step()\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # epoch loss and accuracy\n",
        "  epoch_loss = total_loss / len(dataloader)\n",
        "  # reshape from (no. of batches, size of batch, no. of classes) to (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  print(f\"Train Loss: {epoch_loss:.2f}\")\n",
        "\n",
        "  return epoch_loss, total_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate(model, dataloader, criterion):\n",
        "  \n",
        "  model.eval()\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  total_preds = []\n",
        "\n",
        "  for i, inputs in enumerate((dataloader)):\n",
        "    \n",
        "    # push to gpu\n",
        "    inputs = [t.to(device) for t in inputs]\n",
        "    sent_id, mask, labels = inputs\n",
        "\n",
        "    with torch.no_grad():\n",
        "      preds = model(sent_id, mask)\n",
        "      loss = criterion(preds,labels)\n",
        "      total_loss = total_loss + loss.item()\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # epoch loss and accuracy\n",
        "  epoch_loss = total_loss / len(dataloader) \n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  print(f\"Validation Loss: {epoch_loss:.2f}\")\n",
        "\n",
        "  return epoch_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.70\n",
            "\n",
            " Epoch 2 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 3 / 20\n",
            "Train Loss: 0.68\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 4 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 5 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.67\n",
            "\n",
            " Epoch 6 / 20\n",
            "Train Loss: 0.69\n",
            "Validation Loss: 0.66\n",
            "\n",
            " Epoch 7 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 8 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.64\n",
            "\n",
            " Epoch 9 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.67\n",
            "\n",
            " Epoch 10 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.66\n",
            "\n",
            " Epoch 11 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.65\n",
            "\n",
            " Epoch 12 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.65\n",
            "\n",
            " Epoch 13 / 20\n",
            "Train Loss: 0.68\n",
            "Validation Loss: 0.70\n",
            "\n",
            " Epoch 14 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.72\n",
            "\n",
            " Epoch 15 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.69\n",
            "\n",
            " Epoch 16 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.67\n",
            "\n",
            " Epoch 17 / 20\n",
            "Train Loss: 0.68\n",
            "Validation Loss: 0.67\n",
            "\n",
            " Epoch 18 / 20\n",
            "Train Loss: 0.66\n",
            "Validation Loss: 0.71\n",
            "\n",
            " Epoch 19 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.71\n",
            "\n",
            " Epoch 20 / 20\n",
            "Train Loss: 0.67\n",
            "Validation Loss: 0.68\n"
          ]
        }
      ],
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    train_loss, _ = train(model, train_dataloader, criterion, optimizer)\n",
        "    valid_loss, _ = evaluate(model, val_dataloader, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         9\n",
            "           1       0.59      1.00      0.74        13\n",
            "\n",
            "    accuracy                           0.59        22\n",
            "   macro avg       0.30      0.50      0.37        22\n",
            "weighted avg       0.35      0.59      0.44        22\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\admin\\anaconda3\\envs\\watermelon\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. Model Evaluation\n",
        "\n",
        "The base line model even if htea are less complex then the BERT alghorithem give a good starting point to evaluate how good the final model is. The accuracy of the logistic regression is nearly 68 %. The result is quite imporessive considering the semplicity of the model. \n",
        "\n",
        "Implementing a LSTM layer and using a pretrained algorithem, the hope is to out perform the logistic regression. \n",
        "It is expected that the results in the final model would be better since there are many improvents. Moreover, there is an extra fully connected layerthe in the BERT model that is trained on the specifc data for the task. This should brin´g a significance increase in the overall accuracy. \n",
        "\n",
        "The last step is to fine tuning the model to select the best hyper parameters to achive the best performace. The new accuracy after all the stapes is ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhkmytKNU_Z2"
      },
      "source": [
        "<a name=\"results-and-discussion\"></a>\n",
        "# Results & Discussion\n",
        "\n",
        "In this section, describe and contextualize the results shown in the tutorial. Briefly describe the performance metrics and cross validation techniques used. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LWo6UQzwj37"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHIjM6eMwlXY"
      },
      "source": [
        "Finally, include a discussion on the limitations and important takeaways from the exercise.\n",
        "\n",
        "## Limitations\n",
        "*   The tutorial is focused on education and learning. Explain all the simplifications you have made compared to applying a similar approach in the real world (for instance, if you have reduced your training data and performance).\n",
        "*   ML algorithms and datasets can reinforce or reflect unfair biases. Reflect on the potential biases in the dataset and/or analysis presented in your tutorial, including its potential societal impact, and discuss how readers might go about addressing this challenge. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLLCQpv14Gsx"
      },
      "source": [
        "## Next Steps\n",
        "*   What do you recommend would be the next steps for your readers after finishing your tutorial?\n",
        "*   Discuss other potential policy- and government-related applications for the method or tool discussed in the tutorial.\n",
        "*   List anything else that you would want the reader to take away as they move on from the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkKqewK_-ZLD"
      },
      "source": [
        "<a name=\"references\"></a>\n",
        "# References\n",
        "\n",
        "Include all references used. \n",
        "\n",
        "For example, in this template:\n",
        "\n",
        "*   EarthCube Notebook Template: https://github.com/earthcube/NotebookTemplates\n",
        "*   Earth Engine Community Tutorials Style Guide: https://developers.google.com/earth-engine/tutorials/community/styleguide#colab\n",
        "*   Google Cloud Community Tutorial Style Guide: https://cloud.google.com/community/tutorials/styleguide\n",
        "*   Rule A, Birmingham A, Zuniga C, Altintas I, Huang S-C, Knight R, et al. (2019) Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks. PLoS Comput Biol 15(7): e1007007. https://doi.org/10.1371/journal.pcbi.1007007\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YguJayU8RBmd"
      },
      "source": [
        "## Acknowledgement\n",
        "\n",
        "These guidelines are heavily based on the Climate Change AI template for the for the tutorials track at the [NeurIPS 2021 Workshop on Tackling Climate Change with Machine Learning](https://www.climatechange.ai/events/neurips2021). "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 ('mock_project-G61baSYj')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "fb2d8768065fb97585a7d5029bfebbd6cb54f5dc8d518e72a1bf8e92e54460a1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
