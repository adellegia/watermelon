# Classification of Unstructured Documents: Transfer Learning with BERT


## Summary
In this tutorial, we build a <u>text classification</u> pipeline for unstructured documents using a transformer-based deep learning model called **Bidirectional Encoder Representations from Transformers (BERT)**. We demonstrate the application of a document classification algorithm for the European Commission (EC). 

Whenever new legislation is proposed, the EC opens **public consultations** where various stakeholders (e.g. businesses, academia, law firms, associations, private individuals) submit documents that detail their views on the proposal. The EC receives anywhere between 10,000 to 4 million of these public consultation documents annually. Using machine learning and deep learning methods to process these documents will streamline the Commission's review of stakeholder comments, which will consequently allow them to integrate more information into their policymaking process. 

By the end of this tutorial you will understand how to:  

> 1. Extract, clean, and pre-process information from unstructured PDF documents
> 2. Use the pre-processed text as input to machine learning/deep learning models
> 3. Build a text/document classifier with BERT 
> 4. Compare BERT with text classifiers built using other models


## Contributors
- Ma Adelle Gia Arbo ([GitHub](https://github.com/adellegia))
- Janine De Vera ([GitHub](https://github.com/janinepdevera))
- Lorenzo Gini ([GitHub](https://github.com/zazzooo))
- Lukas Warode ([GitHub](https://github.com/lwarode))
